{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f83751",
   "metadata": {},
   "source": [
    "# **I. Descripción del problema e Inspección del conjunto de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04723445",
   "metadata": {},
   "source": [
    "## **0. Contexto del Dataset**\n",
    "Este dataset es originario del **Sistema de Vigilancia de Salud Pública (SIVIGILA)**, que recopila y analiza datos sobre eventos que afectan la salud de la población colombiana como enfermedades (infecciosas, crónicas, etc.), factores de riesgo y otros sucesos de importancia en salud pública."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9426e2",
   "metadata": {},
   "source": [
    "## **1. Descripción del Problema y Conjunto de datos**\n",
    "\n",
    "### **1.1 Descripción del Problema**\n",
    "\n",
    "El dengue es una enfermedad viral transmitida por mosquitos del género *Aedes*, que constituye una de las principales causas de morbilidad en zonas tropicales. En Colombia, el SIVIGILA recopila de manera continua los casos notificados por las Unidades Primarias Generadoras de Datos (UPGD) en todo el país, consolidando información epidemiológica, demográfica y administrativa de cada caso reportado. Estos registros permiten realizar análisis descriptivos y predictivos sobre el comportamiento de la enfermedad a lo largo del tiempo.\n",
    "\n",
    "El presente trabajo aborda un **problema de regresión**, enfocado en la **predicción del número de casos confirmados de dengue** en Colombia a partir de información epidemiológica registrada en el sistema nacional SIVIGILA durante el periodo **2022–2024**.\n",
    "\n",
    "El propósito del estudio es **modelar el comportamiento semanal de los casos confirmados** de dengue y **estimar la tendencia esperada para el año siguiente (2025)**.\n",
    "\n",
    "Dado que el valor a predecir es **numérico y continuo**, el problema se clasifica dentro del ámbito de la **regresión**, aplicando diferentes enfoques de aprendizaje supervisado para comparar su desempeño:\n",
    "\n",
    "- Regresión multivariada  \n",
    "- Árboles de decisión\n",
    "- Random Forest\n",
    "- Redes neuronales (MLP y DNN)\n",
    "\n",
    "El análisis incluye las etapas de **exploración, limpieza, transformación, modelado y evaluación** del conjunto de datos, con el fin de evaluar el potencial predictivo de cada enfoque y analizar su capacidad de generalización en la predicción del comportamiento epidemiológico del dengue en el país.\n",
    "\n",
    "\n",
    "### **1.2 Descripción del Conjunto de Datos**\n",
    "\n",
    "El conjunto de datos utilizado proviene del portal oficial del **Instituto Nacional de Salud – SIVIGILA**: [https://portalsivigila.ins.gov.co/Paginas/Buscador.aspx](https://portalsivigila.ins.gov.co/Paginas/Buscador.aspx)\n",
    "\n",
    "El dataset contiene los registros de **casos notificados de dengue en Colombia** entre **enero de 2022 y diciembre de 2024**.  \n",
    "Cada fila representa un caso individual reportado a través del sistema de vigilancia epidemiológica, con información demográfica, geográfica, clínica y administrativa.\n",
    "\n",
    "A continuación se describen las variables incluidas en el conjunto de datos del **evento DENGUE (SIVIGILA, Colombia, 2022–2024)**.  \n",
    "Las descripciones se basan principalmente en el **Diccionario de Datos Básicos del SIVIGILA** dadas por el Instituto Nacional de Salud en Colombia, complementadas con inferencias propias cuando el campo no aparece en la documentación oficial.\n",
    "<br>\n",
    "\n",
    "> **Nota:** Las variables marcadas como *No definidas oficialmente* no se encuentran en el Diccionario Básico de Variables del SIVIGILA, pero se incluyen en la base de datos descargada del portal público del sistema. Su interpretación se infiere según el contexto del conjunto de datos.\n",
    "\n",
    "*Diccionario de Datos Básicos del SIVIGILA* Disponible en: [https://www.ins.gov.co/BibliotecaDigital/diccionario-datos-basicos-sivigila.pdf](https://www.ins.gov.co/BibliotecaDigital/diccionario-datos-basicos-sivigila.pdf)\n",
    "\n",
    "### **1.3 Descripción de Variables en el Conjunto de Datos**\n",
    "\n",
    "| Variable | Descripción | Fuente / Observación |\n",
    "|-----------|--------------|----------------------|\n",
    "| `CONSECUTIVE` | Identificador unico por notificación | No definida oficialmente |\n",
    "| `COD_EVE` | Código del evento de vigilancia (210 para Dengue) | Definida oficialmente |\n",
    "| `FEC_NOT` | Fecha de notificación del evento al sistema | Definida oficialmente |\n",
    "| `SEMANA` | Semana epidemiológica según calendarío vigente (Rango: 1-53) | Definida oficialmente |\n",
    "| `ANO` | Año correspondiente a la semana epidemiológica de la notificación | Definida oficialmente |\n",
    "| `COD_PRE` | Código del prestador de servicios de salud | Definida oficialmente |\n",
    "| `COD_SUB` | Código del prestador de servicios de salud - Sub índice | Definida oficialmente |\n",
    "| `EDAD` | Edad del paciente al momento del evento | Definida oficialmente |\n",
    "| `UNI_MED` | Unidad de medida de la edad (1=años, 2=meses, 3=días, 4=horas) | Definida oficialmente |\n",
    "| `nacionalidad` | Código de la nacionalidad del paciente | Definida oficialmente |\n",
    "| `nombre_nacionalidad` | Nombre asociado al código de nacionalidad | No definida oficialmente |\n",
    "| `SEXO` | Sexo biológico del paciente (M=hombre, F=mujer, I=indeterminado) | Definida oficialmente |\n",
    "| `COD_PAIS_O` | Código del país donde ocurrió el evento según estandar internacional | Definida oficialmente |\n",
    "| `COD_DPTO_O` | Código del departamento de ocurrencia según registro Divipola Fuente DANE | Definida oficialmente |\n",
    "| `COD_MUN_O` | Código del municipio de ocurrencia según registro Divipola Fuente DANE | Definida oficialmente |\n",
    "| `AREA` | Tipo de área de residencia (1=cabecera municipal, 2=centro poblado, 3= rural disperso) | Definida oficialmente |\n",
    "| `OCUPACION` | Código de la ocupación del paciente reportada según (Decreto 654 publicado 16 de junio de 2021 y la resolución 0771 del 7 julio de 2021) | Definida oficialmente |\n",
    "| `TIP_SS` | Tipo de régimen en Salud (C=contributivo, S=subsidiado, P=excepción, E=especial, N=no asegurado, I=indeterminado/pendiente) | Definida oficialmente |\n",
    "| `COD_ASE` | Código de la entidad responsable de la atención del paciente | Definida oficialmente |\n",
    "| `PER_ETN` | Código de pertenencia étnica asignado por el DANE | Definida oficialmente |\n",
    "| `GRU_POB` | (Todos sus valores son vacios y no esta definida oficialmente por lo que se dificulta la inferencia del campo) podría tratarse del codigo del grupo de la población étnica | No definida oficialmente |\n",
    "| `nom_grupo` | Indica la población étnica del caso (principalmente grupos indígenas) | No definida oficialmente |\n",
    "| `estrato` | Estrato socioeconómico de residencia | Definida oficialmente |\n",
    "| `GP_DISCAPA` | Indica si la persona presenta discapacidad (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_DESPLAZ` | Indica si la persona es víctima de desplazamiento (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_MIGRANT` | Indica si la persona es migrante (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_CARCELA` | Indica si la persona se encuentra privada de la libertad (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_GESTAN` | Indica si la persona está en estado de gestación (1=si, 2=no) | Definida oficialmente |\n",
    "| `sem_ges` | Semana de gestación en caso de embarazo | Definida oficialmente |\n",
    "| `GP_INDIGEN` | Indica si pertenece a comunidad indígena (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_POBICFB` | Indica si pertenece a población infantil que dependen de la protección y atención del instituto Instituto Colombiano de Bienestar Familiar (ICFB) (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_MAD_COM` | Indica si es madre comunitaria (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_DESMOVI` | Indica si es persona desmovilizada (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_PSIQUIA` | Indica si se encuentra en un centro psiquiátrica o mental (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_VIC_VIO` | Indica si es víctima de violencia (1=si, 2=no) | Definida oficialmente |\n",
    "| `GP_OTROS` | Otro grupo poblacional no especificado (1=si, 2=no) | Definida oficialmente |\n",
    "| `fuente` | Fuente de notificación o registro | Definida oficialmente |\n",
    "| `COD_PAIS_R` | Código del país de residencia según estandar internacional| No definida oficialmente |\n",
    "| `COD_DPTO_R` | Código del departamento de residencia según registro Divipola Fuente DANE | Definida oficialmente |\n",
    "| `COD_MUN_R` | Código del municipio de residencia según registro Divipola Fuente DANE | Definida oficialmente |\n",
    "|  `COD_DPTO_N` | Código del departamento de notificación | No definida oficialmente |\n",
    "| `COD_MUN_N` | Código del municipio de notificación | No Definida oficialmente |\n",
    "| `FEC_CON` | Fecha de consulta médica inicial | Definida oficialmente |\n",
    "| `INI_SIN` | Fecha de inicio de síntomas | Definida oficialmente |\n",
    "| `TIP_CAS` | Clasificación numérica inicial del tipo de caso (1=sospechoso, 2=probable, 3=confirmado laboratorio, 4=confirmado clínica, 5=confirmado por nexo epidemiológico) | Definida oficialmente |\n",
    "| `PAC_HOS` | Indica si el paciente fue hospitalizado (1=si, 2=no) | Definida oficialmente |\n",
    "| `FEC_HOS` | Fecha de hospitalización | Definida oficialmente |\n",
    "| `CON_FIN` | Condición final del paciente (0=no se sabe, 1=vivo, 2=muerto) | Definida oficialmente |\n",
    "|  `FEC_DEF` | Fecha de defunción | Definida oficialmente |\n",
    "| `AJUSTE` | Seguimiento y clasificación final del caso (0=no aplica o no ajusta o 1°vez, 3=confimado por laboratorio, 4=confirmado por clinica, 5=confirmado por nexo epidemiológico, 6=descartado, 7=otro ajuste) | Definida oficialmente |\n",
    "| `FECHA_NTO` | Fecha de nacimiento del paciente | Definida oficialmente |\n",
    "| `CER_DEF` | Numero de certificado de defunción | Definida oficialmente |\n",
    "| `CBMTE` | Causa básica de muerte según el código de Clasificación Internacional de Enfermedades | Definida oficialmente |\n",
    "| `FEC_ARC_XL` | Fecha de archivo o exportación del caso | No definida oficialmente |\n",
    "| `FEC_AJU` | Fecha de ajuste o actualización de caso | Definida oficialmente |\n",
    "| `FM_FUERZA` | Tipo de fuerza (si pertenece a fuerzas armadas) | Definida oficialmente |\n",
    "| `FM_UNIDAD` | Código de la unidad militar según tabla de grados militares | Definida oficialmente |\n",
    "| `FM_GRADO` | Código del grado militar según tabla de grados militares | Definida oficialmente |\n",
    "| `confirmados` | Indica si el caso fue confirmado en alguna etapa del proceso de notificación (variable derivada) | No definida oficialmente (campo calculado a partir de `TIP_CAS` y `AJUSTE`) |\n",
    "| `consecutive_origen` | Consecutivo original de referencia | No definida oficialmente |\n",
    "| `va_sispro` | Variable de validación con sistema SISPRO | No definida oficialmente |\n",
    "| `Estado_final_de_caso` | Código numérico que representa el estado final del caso dentro del sistema de vigilancia | No definida oficialmente (derivada del sistema interno de clasificación) |\n",
    "| `nom_est_f_caso` | Nombre descriptivo del estado final del caso, asociado al valor numérico presente en `Estado_final_de_caso` generada como etiqueta textual complementaria | No definida oficialmente (campo complementario de `Estado_final_de_caso`) |\n",
    "| `Nom_upgd` | Nombre de la Unidad Primaria Generadora de Datos (UPGD) | Definida oficialmente |\n",
    "| `Pais_ocurrencia` | Nombre del País donde ocurrió el evento | No definida oficialmente (campo complementario de `COD_PAIS_O`) |\n",
    "| `Nombre_evento` | Nombre del evento de vigilancia (Dengue). | No definida oficialmente (campo complementario de `COD_EVE`) |\n",
    "| `Departamento_ocurrencia` | Nombre del departamento de ocurrencia | No definida oficialmente (campo complementario de `COD_DPTO_O`) |\n",
    "| `Municipio_ocurrencia` | Nombre del municipio de ocurrencia | No definida oficialmente (campo complementario de `COD_MUN_O`) |\n",
    "| `Pais_residencia` | País de residencia del caso | No definida oficialmente (campo complementario de `COD_PAIS_O` ) |\n",
    "| `Departamento_residencia` | Nombre del departamento de residencia | No definida oficialmente (campo complementario de `COD_DPTO_R` ) |\n",
    "| `Municipio_residencia` | Nombre del municipio de residencia | No definida oficialmente (campo complementario de `COD_MUN_N`) |\n",
    "| `Departamento_Notificacion` | Nombre del departamento de notificación | No definida oficialmente (campo complementario de `COD_DPTO_N`) |\n",
    "| `Municipio_notificacion` | Nombre del municipio de notificación. | No definida oficialmente campo complementario de `COD_MUN_N`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a5b56",
   "metadata": {},
   "source": [
    "### **Importar librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b4acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Esto hace que cada vez que ejecutes una celda, Jupyter verifique si algún módulo local cambió y lo recargue automáticamente.\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Importar las librerías necesarias\n",
    "from ydata_profiling import ProfileReport, compare\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "#importar librerias de sklearn, keras\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras.callbacks import Callback\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "# Agregar el directorio raíz del proyecto al sys.path para permitir importaciones de utilidades realizadas\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Importar el modulo de utilidades desde el paquete src\n",
    "from src import data_utils, visualization_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d40a1",
   "metadata": {},
   "source": [
    "### **Carga Datos**\n",
    "En esta sección se realiza la conversión de formato a los archivos descargados desde el portal del SIVIGILA, utilizando el módulo de utilidades.\n",
    "Con la finalidad de acelerar el proceso posterior de cargado y lectura, dicha conversión se hará de formato .xlsx -> formato .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d85235",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.convertir_excel_a_parquet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7149e70",
   "metadata": {},
   "source": [
    "Una vez realizada la conversión procedemos a cargar los datos en un diccionario usando el módulo de utilidades, de esta manera obtendremos los nombres de los archivos asociados a sus respectivos dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb985df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = data_utils.cargar_archivos_parquet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6f98e",
   "metadata": {},
   "source": [
    "Verificamos si existen inconsistencias en las columnas de los distintos DataFrames para realizar una primera inspección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref, columnas_en_comun = data_utils.verificar_referencia_columnas(dict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb7308",
   "metadata": {},
   "source": [
    "A partir de esta revisión, se concluye que la única inconsistencia identificada a nivel de columnas corresponde al campo consecutive_origen, el cual no se encuentra en el archivo de datos de 2024 pero sí en los de 2022 y 2023.\n",
    "Asimismo, se confirma que no existen columnas duplicadas ni diferencias en los nombres de las variables entre los conjuntos de datos.\n",
    "En consecuencia, procederemos a unir los DataFrames en un único conjunto consolidado, con el fin de realizar el análisis exploratorio y las etapas posteriores de limpieza y procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_utils.unir_df(dict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ec45f",
   "metadata": {},
   "source": [
    "### **1.4 Análisis Exploratorio Inicial**\n",
    "Realizaremos un primer Exploratory Data Analysis (EDA) sobre los datos crudos después de unir los Dataframes con el objetivo de entender la naturaleza y calidad del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(\n",
    "    df, \n",
    "    title=\"Perfil inicial de los datos crudos\", \n",
    "    minimal=True, \n",
    "    progress_bar=False\n",
    ")\n",
    "\n",
    "report_dir = \"reports/01_initial_data_profile.html\"\n",
    "report_path = project_root / report_dir\n",
    "\n",
    "profile.to_file(report_path)\n",
    "profile.to_notebook_iframe()\n",
    "\n",
    "nombre = \"Reporte inicial de los datos crudos\"\n",
    "visualization_utils.show_report_link(report_dir, nombre)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68435ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516e8bf",
   "metadata": {},
   "source": [
    "El dataset consta de 501.729 registros y 73 columnas, correspondientes a los casos reportados de Dengue en Colombia entre 2022 y 2024. A partir del primer acercamiento realizado, se identificaron diversos aspectos relevantes que se describen a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8fcb03",
   "metadata": {},
   "source": [
    "#### **Variables con valores constantes**\n",
    "\n",
    "Durante el periodo 2022–2024, se identifican campos que mantienen valores constantes, como lo son:\n",
    "\n",
    "| Variable | Valor constante | Descripción |\n",
    "|-----------|----------------|--------------|\n",
    "| `COD_EVE` | 210 | Código del evento “DENGUE” |\n",
    "| `CON_FIN` | 1 | Estado final “Vivo” |\n",
    "| `va_sispro` | 1 | Bandera técnica SISPRO |\n",
    "| `Nombre_evento` | DENGUE | Nombre del evento |\n",
    "\n",
    "<br>\n",
    "\n",
    "- **COD_EVE:**\n",
    "<br>\n",
    "Representa el código del evento de interés en salud pública. Todos los registros presentan el valor 210, correspondiente a DENGUE.\n",
    "\n",
    "- **CON_FIN:**  \n",
    "Describe la condición final del paciente. En este conjunto de datos, todos los registros tienen el valor **1 (“Vivo”)**.  \n",
    "    > **Nota:** Esto no implica la ausencia de fallecimientos por dengue en el periodo analizado, sino que el conjunto de datos de este estudio no incluye los casos graves que podrían encontrarse en bases específicas del SIVIGILA.\n",
    "\n",
    "- **va_sispro:**\n",
    "<br>\n",
    "No figura en el diccionario oficial. Por su comportamiento constante y su denominación, se interpreta como una bandera técnica de interoperabilidad entre **SIVIGILA** y **SISPRO**, sin relevancia analítica.\n",
    "\n",
    "- **Nombre_evento:**\n",
    "<br>\n",
    "Contiene el valor constante “DENGUE”, correspondiente a la patología de estudio.\n",
    "\n",
    ">##### **Conclusión:**  Estas variables (`COD_EVE`, `Nombre_evento`, `va_sispro`, `CON_FIN`) serán **excluidas** del análisis por tratarse de campos de poco valor analítico, técnicos o sin variabilidad.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e930fe",
   "metadata": {},
   "source": [
    "#### **Variables técnicas o administrativas**\n",
    "\n",
    "Existen campos no descritos en el diccionario oficial o con finalidad administrativa, cuya función principal parece estar relacionada con el control interno, trazabilidad o gestión del sistema de información, más que con el análisis epidemiológico:\n",
    "\n",
    "- **CONSECUTIVE:**  \n",
    "  No documentada oficialmente. Presenta valores únicos, lo que sugiere que funciona como un identificador interno del sistema.  \n",
    "  Se considera una variable técnica sin valor analítico.\n",
    "\n",
    "- **CONSECUTIVE_ORIGIN:**  \n",
    "  No documentada oficialmente. Contiene valores repetidos, lo que sugiere que actúa como un identificador de la fuente de origen del caso. Se considera una variable de trazabilidad, no analítica.\n",
    "\n",
    "- **COD_ASE:**  \n",
    "  Representa el código de la entidad responsable de la atención del paciente del caso notificado. Sus valores (por ejemplo, `EPS41`, `EPS51`, etc.) corresponden a identificadores internos del sistema de salud y no aportan información relevante para el análisis del evento o del paciente. Por tanto, se considera un campo administrativo sin utilidad analítica.\n",
    "\n",
    ">##### **Conclusión:**  Estas variables (`CONSECUTIVE`, `CONSECUTIVE_ORIGIN`, `COD_ASE`) serán **excluidas** del análisis por tratarse de campos administrativos o técnicos destinados al control y trazabilidad del sistema, sin aporte informativo para el estudio epidemiológico.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a9c59",
   "metadata": {},
   "source": [
    "#### **Variables vacías o con alta proporción de valores faltantes**\n",
    "\n",
    "- **GRU_POB:**\n",
    "<br>\n",
    "No presenta valores en ningún registro del periodo 2022–2024, por lo que será descartada.\n",
    "\n",
    "- **FEC_DEF, CER_DEF y CBMTE:**\n",
    "<br>\n",
    "No contienen valores. Dado que este conjunto no incluye casos fatales, estas variables no son relevantes para el análisis.\n",
    "\n",
    "- **FM_FUERZA, FM_UNIDAD y FM_GRADO:**\n",
    "<br>\n",
    "Relacionadas con la pertenencia militar del paciente. El 99.4% de los registros presentan valores vacíos, por lo que serán excluidas por falta de información y baja relevancia analítica.\n",
    "\n",
    ">##### **Conclusión:** Estas variables (`GRU_PO`, `FEC_DEF`, `CER_DEF`, `CBMTE`, `FM_FUERZA`, `FM_UNIDAD`, `FM_GRADO`) serán **excluidas** del análisis por tratarse de campos vacios o con alta proporción de valores faltantes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f9e79",
   "metadata": {},
   "source": [
    "#### **Variables con formatos inconsistentes**\n",
    "\n",
    "Durante la inspección inicial de los tipos de datos se identificaron algunas variables que presentan **inconsistencias en su formato**, lo que podría afectar operaciones estadísticas o gráficas si no se ajustan.  \n",
    "\n",
    "Las principales observaciones son las siguientes:\n",
    "\n",
    "- **OCUPACION:**  \n",
    "  Contiene valores numéricos que representan códigos de ocupación, pero fueron cargados como tipo **`object` (texto)**.  \n",
    "\n",
    "- **ESTRATO:**  \n",
    "  Registrada como tipo **`object` (texto)**, aunque corresponde a un valor **numérico discreto** (1–6) que clasifica el nivel socioeconómico.  \n",
    "\n",
    "- **SEM_GES:**  \n",
    "  Relacionada con el número de **semanas de gestación**. Se encuentra en formato **texto**, y combina valores numéricos con vacíos (esperables en registros no aplicables).  \n",
    "\n",
    "Estas diferencias se deben a la **integración de fuentes heterogéneas (2022–2024)**, donde algunas variables presentan **tipos mixtos** o vacíos.  \n",
    "Por ejemplo:  \n",
    "- `OCUPACION` mezcla valores *int* y *float*\n",
    "- `SEM_GES` combina *int*, *float* y campos vacíos  \n",
    "- `ESTRATO` contiene *int*, *float* y campos vacíos\n",
    "\n",
    "En caso de requerirse un tratamiento posterior, estas columnas podrían convertirse a tipos numéricos compatibles con valores nulos (`float` o `Int64`) para mantener la coherencia.  \n",
    "\n",
    ">##### **Conclusión:** Las variables (`OCUPACION`, `ESTRATO`, `SEM_GES`) presentan inconsistencias de formato, pero aportan información complementaria sobre las características sociodemográficas y clínicas de los casos. Si bien su análisis puede ofrecer una comprensión más amplia del comportamiento del dengue en ciertos grupos poblacionales, **no constituyen el foco principal del estudio** por lo que serán **excluidas** del análisis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0b087",
   "metadata": {},
   "source": [
    "#### **Normalización de la variable de edad**\n",
    "\n",
    "El conjunto de datos incluye información de edad reportada en dos columnas separadas:\n",
    "\n",
    "- `EDAD`: valor numérico de la edad.  \n",
    "- `UNI_MED`: unidad de medida en la que se expresa la edad (por ejemplo, días, meses o años).\n",
    "\n",
    "Para garantizar la consistencia en el análisis y evitar ambigüedades, se realizará una **conversión de todas las edades a una unidad común**, expresada en **años**.\n",
    "\n",
    "El procedimiento consistirá en:\n",
    "\n",
    "1. Identificar la unidad correspondiente en `UNI_MED`:\n",
    "   - 1 -> Años  \n",
    "   - 2 -> Meses  \n",
    "   - 3 -> Días\n",
    "   - 4 -> Horas\n",
    "\n",
    "2. Estandarizar el valor de `EDAD` a años mediante:\n",
    "   - `EDAD_final = EDAD` (si unidad = años)  \n",
    "   - `EDAD_final = EDAD / 12` (si unidad = meses)  \n",
    "   - `EDAD_final = EDAD / 365` (si unidad = días)\n",
    "   - `EDAD_final = EDAD / 8760` (si unidad = horas)\n",
    "\n",
    "3. Crear una nueva variable denominada `EDAD_ANIOS`, que contendrá la edad estandarizada.\n",
    "\n",
    ">##### **Conclusión:** Se unificará la información de edad en una sola variable (`EDAD_ANIOS`), expresada consistentemente en años, lo que permitirá realizar análisis comparables y visualizaciones precisas por grupos etarios.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6cf5bb",
   "metadata": {},
   "source": [
    "#### **Estandarización de nombres de variables**\n",
    "\n",
    "Con el fin de **facilitar la manipulación del dataset** y **evitar errores de escritura** durante el proceso de análisis, se realizará la estandarización de los nombres de las columnas.  \n",
    "\n",
    "El conjunto de datos original contiene nombres en **mayúsculas**, con algunos campos escritos parcialmente en diferentes formatos o con variaciones de estilo (por ejemplo, `FEC_NOT`, `Estado_final_de_caso`, `confirmados`).  \n",
    "Estas diferencias pueden generar confusión o errores al momento de realizar consultas, transformaciones o fusiones de datos.\n",
    "\n",
    "Por ello, todos los nombres de las columnas serán **convertidos a minúsculas** de manera uniforme.  \n",
    "\n",
    " **Ejemplo:**\n",
    "    - `FEC_NOT` -> `fec_not`  \n",
    "    - `TIP_CAS` -> `tip_cas`  \n",
    "    - `Nom_upgd` -> `nom_upgd`\n",
    "\n",
    "Este cambio no afecta el contenido ni la interpretación de las variables, pero mejora la **legibilidad** y **consistencia**, además de reducir la probabilidad de errores en llamadas a columnas dentro de funciones de análisis o visualización.\n",
    "\n",
    ">##### **Conclusión:** Se normalizarán todos los nombres de variables a **minúsculas**, garantizando coherencia, facilidad de uso y menor probabilidad de errores tipográficos durante el análisis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d6f5e",
   "metadata": {},
   "source": [
    "> **Conclusión sobre la variable `confirmados`:**  \n",
    "> Aunque la variable `confirmados` no aparece en el diccionario oficial del **SIVIGILA**, su comportamiento dentro del conjunto de datos sugiere que fue generada de manera derivada para identificar casos **confirmados en cualquier momento del proceso de notificación**.  \n",
    ">\n",
    "> En el sistema SIVIGILA, la variable `TIP_CAS` representa la **clasificación inicial del caso** (por ejemplo: *Sospechoso*, *Probable*, *Confirmado*), mientras que `AJUSTE` corresponde a la **clasificación final o de ajuste**, realizada tras el proceso de verificación y validación.  \n",
    ">\n",
    "> La variable `confirmados` parece sintetizar esta información, marcando con valor **1** aquellos registros que fueron confirmados en cualquiera de las etapas, ya sea desde el inicio (`TIP_CAS`) o tras el ajuste (`AJUSTE`).  \n",
    ">\n",
    "> Tras una verificación entre estos tres campos (`TIP_CAS`, `AJUSTE` y `confirmados`), se comprobó que el comportamiento de `confirmados` coincide con los patrones esperados para representar el **estatus de confirmación del caso**.  \n",
    ">\n",
    "> Por tanto, aunque no es una variable oficial, su **consistencia interna valida su uso como indicador auxiliar de confirmación**, y puede emplearse para filtrar casos confirmados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05bf993",
   "metadata": {},
   "source": [
    "## **2. Inspección o Exploración del Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe9b3a0",
   "metadata": {},
   "source": [
    "Una vez comprendida la estructura y naturaleza de las variables, se procede a realizar la **inspección exploratoria del dataset**, con el propósito de identificar patrones y comportamientos. Esta etapa constituye un paso fundamental dentro del **análisis exploratorio de datos (EDA)**, ya que permite obtener una visión preliminar del comportamiento de las variables, su distribución y relaciones entre ellas.  \n",
    "\n",
    "Para ello, se aplicarán herramientas de **visualización gráfica** (como histogramas, diagramas de barras, mapas de calor y nubes de palabras), así como **resúmenes estadísticos** que faciliten la interpretación cuantitativa de los datos.  \n",
    "\n",
    "De manera complementaria, se incluirá una **matriz de correlación** para evaluar la relación entre las variables numéricas y detectar posibles redundancias o asociaciones relevantes para los modelos predictivos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bfae84",
   "metadata": {},
   "source": [
    "### **2.1 Panorama general Nacional**\n",
    "\n",
    "El análisis nacional del dengue en Colombia permite observar la magnitud y el comportamiento del evento a lo largo del tiempo y el territorio. En este apartado se presentan las tendencias temporales y espaciales más relevantes, comenzando con la evolución mensual de casos a nivel nacional y por sexo, para luego identificar los patrones estacionales y la dinámica semanal del evento. Finalmente, se incluyen representaciones geográficas que evidencian la distribución de los casos en el país y los departamentos con mayor carga de enfermedad, ofreciendo una visión integral de la situación epidemiológica del dengue en Colombia durante el periodo de estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANORAMA GENERAL NACIONAL - DENGUE\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Asegurar tipo datetime\n",
    "df[\"FEC_NOT\"] = pd.to_datetime(df[\"FEC_NOT\"], errors=\"coerce\")\n",
    "\n",
    "# 1 Evolución mensual total\n",
    "df_time = (\n",
    "    df.groupby(df[\"FEC_NOT\"].dt.to_period(\"M\"))\n",
    "    .size()\n",
    "    .reset_index(name=\"Casos\")\n",
    ")\n",
    "df_time[\"FEC_NOT\"] = df_time[\"FEC_NOT\"].dt.to_timestamp()\n",
    "\n",
    "axes[0].plot(df_time[\"FEC_NOT\"], df_time[\"Casos\"], marker=\"o\", color=\"steelblue\")\n",
    "axes[0].set_title(\"Evolución mensual total de casos notificados de dengue\")\n",
    "axes[0].set_xlabel(\"Fecha de notificación\")\n",
    "axes[0].set_ylabel(\"Número de casos\")\n",
    "axes[0].set_xlim(df_time[\"FEC_NOT\"].min(), df_time[\"FEC_NOT\"].max())\n",
    "\n",
    "# 2 Evolución mensual por sexo\n",
    "casos_sexo = (\n",
    "    df.groupby([df[\"FEC_NOT\"].dt.to_period(\"M\"), \"SEXO\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "casos_sexo[\"FEC_NOT\"] = casos_sexo[\"FEC_NOT\"].dt.to_timestamp()\n",
    "\n",
    "axes[1].plot(casos_sexo[\"FEC_NOT\"], casos_sexo[\"M\"], label=\"Hombres\", color=\"skyblue\")\n",
    "axes[1].plot(casos_sexo[\"FEC_NOT\"], casos_sexo[\"F\"], label=\"Mujeres\", color=\"orange\")\n",
    "axes[1].set_title(\"Evolución mensual por sexo de casos notificados de dengue\")\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim(casos_sexo[\"FEC_NOT\"].min(), casos_sexo[\"FEC_NOT\"].max())\n",
    "\n",
    "# 3 Patrón estacional (polinomial por semana)\n",
    "semana_counts = df.groupby('SEMANA').size().reset_index(name='casos')\n",
    "z = np.polyfit(semana_counts['SEMANA'], semana_counts['casos'], 7)\n",
    "p = np.poly1d(z)\n",
    "x_smooth = np.linspace(1, 52, 200)\n",
    "y_smooth = p(x_smooth)\n",
    "\n",
    "axes[2].scatter(semana_counts['SEMANA'], semana_counts['casos'], color=\"#FF6B35\", alpha=0.6)\n",
    "axes[2].plot(x_smooth, y_smooth, color=\"#D63031\", lw=2.5)\n",
    "axes[2].set_title(\"Patrón estacional de casos notificados de dengue\")\n",
    "axes[2].set_xlabel(\"Semana epidemiológica\")\n",
    "axes[2].set_xlim(semana_counts['SEMANA'].min(), semana_counts['SEMANA'].max())\n",
    "\n",
    "# 4 Distribución semanal por año\n",
    "casos_semana = df.groupby([\"ANO\", \"SEMANA\"]).size().reset_index(name=\"Casos\")\n",
    "sns.scatterplot(data=casos_semana, x=\"SEMANA\", y=\"Casos\", hue=\"ANO\", ax=axes[3], palette=\"viridis\", s=40)\n",
    "axes[3].set_title(\"Distribución de casos notificados de dengue por semana y año\")\n",
    "axes[3].legend(title=\"Año\")\n",
    "axes[3].set_xlabel(\"Semana epidemiológica\")\n",
    "axes[3].set_xlim(casos_semana[\"SEMANA\"].min(), casos_semana[\"SEMANA\"].max())\n",
    "\n",
    "# 5 Mapa de calor por departamento\n",
    "casos_departamento = (\n",
    "    df.groupby(\"COD_DPTO_O\")\n",
    "    .size()\n",
    "    .reset_index(name=\"num_casos\")\n",
    ")\n",
    "casos_departamento[\"COD_DPTO_O\"] = casos_departamento[\"COD_DPTO_O\"].astype(str).str.zfill(2)\n",
    "\n",
    "gdf = gpd.read_file(\"../data/raw/Colombia.geojson\")\n",
    "gdf[\"DPTO\"] = gdf[\"DPTO\"].astype(str).str.zfill(2)\n",
    "gdf_merged = gdf.merge(casos_departamento, left_on=\"DPTO\", right_on=\"COD_DPTO_O\", how=\"left\")\n",
    "\n",
    "gdf_merged.plot(column=\"num_casos\", ax=axes[4], legend=True, cmap=\"Reds\", edgecolor=\"black\", linewidth=0.5)\n",
    "axes[4].set_title(\"Mapa de calor por departamento\")\n",
    "axes[4].axis(\"off\")\n",
    "\n",
    "# 6 Top 10 departamentos\n",
    "casos_dep = df[\"Departamento_ocurrencia\"].value_counts().head(10)\n",
    "sns.barplot(x=casos_dep.values, y=casos_dep.index, palette=\"Spectral\", ax=axes[5], hue=casos_dep.index, legend=False)\n",
    "axes[5].set_title(\"Top 10 departamentos con más casos ocurridos de dengue\")\n",
    "axes[5].set_xlabel(\"Número de casos\")\n",
    "axes[5].set_ylabel(\"Departamento\")\n",
    "\n",
    "# Ajuste de diseño y título general\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Panorama General Nacional — Dengue en Colombia\", fontsize=18, fontweight=\"bold\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8158394",
   "metadata": {},
   "source": [
    "El análisis nacional del dengue en Colombia entre **2022 y 2024** evidencia un **crecimiento sostenido** de los casos desde 2022 hasta finales de 2023, seguido de un **aumento abrupto a comienzos de 2024**, cuando la notificación de casos se dispara de forma exponencial. Este incremento coincide con el **Fenómeno de El Niño (2023–2024)**, evento que, según el **Ministerio de Salud y Protección Social de Colombia** ([fuente oficial](https://www.minsalud.gov.co/Paginas/el-nino-no-es-un-juego.aspx)), **favoreció la expansión del vector *Aedes aegypti*** debido a las altas temperaturas y al almacenamiento doméstico de agua durante los periodos de sequía, generando criaderos artificiales que impulsaron la transmisión del virus.\n",
    "\n",
    "La **distribución semanal** por año evidencia que los periodos de mayor transmisión se concentran, de forma consistente, entre las **semanas epidemiológicas 15 y 30**. Durante **2022 y 2023** se observa un patrón de aumento progresivo y regular dentro de ese intervalo. Sin embargo, en **2024** se presenta una ruptura de la estacionalidad, caracterizada por un repunte atípico y desproporcionado desde las primeras semanas del año, que altera el patrón promedio histórico y solo comienza a estabilizarse hacia la **semana 30.**\n",
    "\n",
    "A nivel territorial, los **departamentos de Valle del Cauca, Santander, Tolima, Bolívar y Meta** concentran la mayor carga de casos, evidenciando que el brote tuvo un impacto especialmente fuerte en el suroccidente y centro del país. En el análisis por sexo, los **casos en hombres y mujeres evolucionan de manera paralela**, con una **ligera diferencia a favor de las mujeres** únicamente durante el pico epidémico de 2024.\n",
    "\n",
    "El comportamiento descrito respalda la pertinencia de **agrupar los casos por semana epidemiológica** como base para el **análisis temporal y predictivo del dengue en Colombia**. Este nivel de desagregación permite identificar con mayor precisión los **picos de transmisión** y las **fluctuaciones estacionales**, además de facilitar la **construcción de modelos de predicción** que estimen el número probable de casos en semanas futuras (por ejemplo, **Semana 3 de 2025**).  \n",
    "De esta manera, se optimiza la capacidad de **vigilancia epidemiológica**, fortaleciendo los mecanismos de **alerta temprana** y la **planificación de intervenciones preventivas** en salud pública.\n",
    "\n",
    "> **Nota:** Para este propósito, se empleará la **variable de fecha de notificación (`FEC_NOT`)**, la cual será **agrupada por semana epidemiológica** para generar una **nueva variable temporal (`FECHA_SEMANA`)** que representa el **inicio de cada semana** del periodo analizado.  \n",
    "> Este enfoque conserva la **continuidad temporal** y permite construir una **serie de tiempo semanal** en la que cada punto corresponde al número total de casos notificados durante esa semana.  \n",
    "> Adicionalmente, se identifican registros correspondientes al año **2025**, aunque la fuente oficial indica cobertura hasta 2024.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363c62c",
   "metadata": {},
   "source": [
    "### **2.2 Análisis Demográfico**\n",
    "\n",
    "El análisis demográfico del dengue en Colombia permite caracterizar el perfil poblacional de las personas afectadas y explorar posibles diferencias asociadas con la edad, el sexo y otros factores sociales.  \n",
    "En este apartado se examina la distribución de los casos según variables individuales relevantes, iniciando con la **distribución de edad** y su comparación por **sexo**. Posteriormente, se analiza la **evolución de la edad promedio** a lo largo del tiempo, con el fin de determinar si los cambios en la dinámica epidemiológica del evento han modificado el perfil de edad de los casos.  \n",
    "Finalmente, se incluyen representaciones que describen el **contexto poblacional y étnico** de los casos notificados, mediante la **distribución por grupo poblacional** y una **nube de palabras de grupos étnicos**, proporcionando una visión complementaria del componente social y cultural asociado al dengue en el país.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2cf275",
   "metadata": {},
   "source": [
    "> **Nota:** Antes de realizar la exploración visual y estadística, se efectuaran ajustes mínimos de formato con el objetivo de garantizar la correcta lectura del conjunto de datos y permitir un análisis etario adecuado.  \n",
    "> Estos ajustes incluyen lo mencionado en el apartado **Normalización de la variable de edad**.  \n",
    "> No se realizarán por el momento otras transformaciones ni modificaciones estructurales, las cuales se abordarán formalmente en el apartado de *Preparación de los datos*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44299510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columna EDAD_ANIOS como float desde el inicio\n",
    "df[\"EDAD_ANIOS\"] = df[\"EDAD\"].astype(float)\n",
    "\n",
    "# Conversión según la unidad de edad (UNI_MED)\n",
    "df.loc[df[\"UNI_MED\"] == 2, \"EDAD_ANIOS\"] = df[\"EDAD\"] / 12       # meses -> años\n",
    "df.loc[df[\"UNI_MED\"] == 3, \"EDAD_ANIOS\"] = df[\"EDAD\"] / 365      # días -> años\n",
    "df.loc[df[\"UNI_MED\"] == 4, \"EDAD_ANIOS\"] = df[\"EDAD\"] / 8760     # horas -> años\n",
    "\n",
    "# Convertir valores no numéricos a NaN (por si acaso)\n",
    "df[\"EDAD_ANIOS\"] = pd.to_numeric(df[\"EDAD_ANIOS\"], errors=\"coerce\")\n",
    "\n",
    "# Redondear a dos decimales\n",
    "df[\"EDAD_ANIOS\"] = df[\"EDAD_ANIOS\"].round(2)\n",
    "\n",
    "\n",
    "# ANÁLISIS DEMOGRÁFICO\n",
    "\n",
    "# Asegurar formato datetime\n",
    "df[\"FEC_NOT\"] = pd.to_datetime(df[\"FEC_NOT\"], errors=\"coerce\")\n",
    "\n",
    "# Crear figura general\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 1 Distribución de edad (histograma)\n",
    "sns.histplot(\n",
    "    df[\"EDAD_ANIOS\"], # type: ignore\n",
    "    bins=np.arange(0, df[\"EDAD_ANIOS\"].max(), 5), \n",
    "    kde=True, color=\"green\", ax=axes[0]) \n",
    "axes[0].set_title(\"Distribución de edad de los casos reportados\")\n",
    "axes[0].set_xlabel(\"Edad (años)\")\n",
    "axes[0].set_ylabel(\"Frecuencia\")\n",
    "axes[0].set_xticks(np.arange(0, df[\"EDAD_ANIOS\"].max(), 10))\n",
    "axes[0].set_xlim(0)\n",
    "\n",
    "# 2 Distribución de edad por sexo (boxplot)\n",
    "sns.boxplot(data=df, x=\"SEXO\", y=\"EDAD_ANIOS\", palette=\"Set3\", ax=axes[1], hue=\"SEXO\", legend=False)\n",
    "axes[1].set_title(\"Distribución de edad por sexo\")\n",
    "axes[1].set_xlabel(\"Sexo\")\n",
    "axes[1].set_ylabel(\"Edad (años)\")\n",
    "\n",
    "# 3 Evolución de la edad promedio\n",
    "edad_mes = (\n",
    "    df.groupby(df[\"FEC_NOT\"].dt.to_period(\"M\"))[\"EDAD_ANIOS\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"PROMEDIO_EDAD\")\n",
    ")\n",
    "edad_mes[\"FEC_NOT\"] = edad_mes[\"FEC_NOT\"].dt.to_timestamp()\n",
    "\n",
    "axes[2].plot(edad_mes[\"FEC_NOT\"], edad_mes[\"PROMEDIO_EDAD\"], marker=\"o\", color=\"#2980B9\")\n",
    "axes[2].set_title(\"Evolución de la edad promedio (mensual)\")\n",
    "axes[2].set_xlabel(\"Mes\")\n",
    "axes[2].set_ylabel(\"Edad promedio (años)\")\n",
    "axes[2].tick_params(axis=\"x\", rotation=45)\n",
    "axes[2].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "axes[2].set_xlim(edad_mes[\"FEC_NOT\"].min(), edad_mes[\"FEC_NOT\"].max())\n",
    "\n",
    "# 4 Distribución por grupo poblacional (pie chart)\n",
    "gp_cols = [col for col in df.columns if col.startswith(\"GP_\") and col != \"GP_OTROS\"]\n",
    "gp_summary = df[gp_cols].apply(lambda x: (x == 1).sum()).sort_values(ascending=False) # type: ignore\n",
    "\n",
    "colors = plt.cm.tab10(range(len(gp_summary))) # type: ignore\n",
    "\n",
    "wedges, texts = axes[3].pie(\n",
    "    gp_summary.values,\n",
    "    colors=colors,\n",
    "    startangle=90,\n",
    "    counterclock=False\n",
    ")\n",
    "axes[3].set_title(\"Distribución de casos por grupo poblacional\")\n",
    "\n",
    "# Etiquetas con porcentajes\n",
    "labels = [f\"{g} ({v / gp_summary.sum() * 100:.1f}%)\" for g, v in zip(gp_summary.index, gp_summary.values)]\n",
    "axes[3].legend(wedges, labels, title=\"Grupo poblacional\", loc=\"best\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# 5 Nube de palabras (grupos étnicos)\n",
    "texto_grupos = \" \".join(df[\"nom_grupo\"].dropna().astype(str))\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=500,\n",
    "    background_color=\"white\",\n",
    "    colormap=\"magma\",\n",
    "    collocations=False,\n",
    "    max_words=100\n",
    ").generate(texto_grupos)\n",
    "\n",
    "axes[4].imshow(wordcloud, interpolation=\"bilinear\")\n",
    "axes[4].axis(\"off\")\n",
    "axes[4].set_title(\"Nube de palabras — Grupos étnicos reportados\")\n",
    "\n",
    "# Ocultar el subplot vacío (el 6°)\n",
    "axes[5].axis(\"off\")\n",
    "\n",
    "# Ajustar diseño general\n",
    "fig.suptitle(\"Análisis Demográfico — Dengue en Colombia\", fontsize=18, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f248cd1",
   "metadata": {},
   "source": [
    "En Colombia, la **mayor concentración de casos de dengue** se presenta en **personas jóvenes**, con un pico alrededor de los **20 años**. Este patrón se observa principalmente en **casos de dengue no grave**, que afectan más a jóvenes y adultos jóvenes. Los **adultos mayores** podrían estar subrepresentados, ya que tienden a presentar formas más severas de la enfermedad.\n",
    "\n",
    "La **distribución de edad por sexo** es **simétrica entre hombres y mujeres**, sin diferencias significativas en mediana ni dispersión, indicando que la afectación por edad es **independiente del sexo**.\n",
    "\n",
    "La **edad promedio mensual** muestra una **tendencia ascendente desde 2022**, alcanzando un máximo a mediados de 2024 durante el periodo epidémico más intenso, y disminuye hacia finales del año, sugiriendo un aumento relativo de casos en adultos jóvenes durante el brote.\n",
    "\n",
    "Respecto a la **distribución por grupo poblacional** (excluyendo el grupo \"otros\"), los **migrantes** y las **personas desplazadas** presentan las proporciones más altas dentro de los grupos específicos, con **43.3%** y **15.7%**, respectivamente. Esto refleja que los grupos más vulnerables, con acceso limitado a servicios básicos y mayor exposición a entornos de riesgo, tienden a presentar mayor incidencia de dengue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48be46",
   "metadata": {},
   "source": [
    "### **2.3 Análisis de Casos por Área y Evolución Temporal**\n",
    "\n",
    "Esta sección examina cómo se distribuyen los casos de dengue según el tipo de área **(cabecera municipal, centro poblado y rural disperso)** y cómo evolucionan a lo largo del tiempo. Se destacan las diferencias en la incidencia entre áreas y los patrones temporales de los brotes, incluyendo la identificación de periodos con mayor número de casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS DE CASOS POR ÁREA Y EVOLUCIÓN TEMPORAL\n",
    "\n",
    "# Etiquetas descriptivas para tipo de área\n",
    "area_labels = {1: \"Cabecera municipal\", 2: \"Centro poblado\", 3: \"Rural disperso\"}\n",
    "\n",
    "# Crear figura con 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 1 Casos notificados por tipo de área (pie chart)\n",
    "ocur_nacional = (\n",
    "    df.assign(AREA_DESC=df[\"AREA\"].map(area_labels))\n",
    "      .groupby(\"AREA_DESC\")\n",
    "      .size()\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "axes[0].pie(\n",
    "    ocur_nacional,\n",
    "    labels=ocur_nacional.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    counterclock=False,\n",
    "    colors=sns.color_palette(\"pastel\")\n",
    ")\n",
    "axes[0].set_title(\"Casos notificados por tipo de área\", fontsize=11)\n",
    "\n",
    "# 2 Evolución temporal de casos notificados por tipo de área (lineplot)\n",
    "serie_area = (\n",
    "    df.assign(\n",
    "        AREA_DESC=df[\"AREA\"].map(area_labels),\n",
    "        MES=df[\"FEC_NOT\"].dt.to_period(\"M\")\n",
    "    )\n",
    "    .groupby([\"MES\", \"AREA_DESC\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"Casos\")\n",
    "    .assign(FECHA=lambda x: x[\"MES\"].dt.to_timestamp())\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=serie_area,\n",
    "    x=\"FECHA\",\n",
    "    y=\"Casos\",\n",
    "    hue=\"AREA_DESC\",\n",
    "    marker=\"o\",\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Evolución mensual por casos notificados por tipo de área\", fontsize=11)\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "axes[1].set_xlabel(\"Mes\")\n",
    "axes[1].set_ylabel(\"Casos\")\n",
    "axes[1].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "axes[1].legend(title=\"Tipo de área\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "axes[1].set_xlim(serie_area[\"FECHA\"].min(), serie_area[\"FECHA\"].max())\n",
    "\n",
    "\n",
    "# 3 Mapa de calor de casos notificados por año y mes\n",
    "pivot = (\n",
    "    df.groupby([df[\"FEC_NOT\"].dt.year, df[\"FEC_NOT\"].dt.month])\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "sns.heatmap(\n",
    "    pivot,\n",
    "    cmap=\"YlOrRd\",\n",
    "    ax=axes[2],\n",
    "    cbar_kws={\"label\": \"Número de casos\"}\n",
    ")\n",
    "axes[2].set_title(\"Mapa de calor de casos notificados por mes y año\", fontsize=11)\n",
    "axes[2].set_xlabel(\"Mes\")\n",
    "axes[2].set_ylabel(\"Año\")\n",
    "\n",
    "# Ajustes finales de la figura\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Análisis de Casos por Área y Evolución Temporal - Dengue en Colombia\", fontsize=16, fontweight=\"bold\", y=1.03)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b6e34",
   "metadata": {},
   "source": [
    "En el análisis por tipo de área, la **mayor proporción de casos** de dengue ocurre en la **cabecera municipal (82.7%)**, seguida por las áreas **rurales dispersas (10.7%)** y los **centros poblados (6.6%)**. Esta concentración urbana probablemente se relaciona con la **mayor densidad de población**, la **proximidad entre viviendas** y la **mayor capacidad de notificación de casos** en cabeceras municipales, mientras que en áreas rurales y centros poblados la dispersión de la población y el acceso limitado a servicios de salud podrían reducir la detección de casos.\n",
    "\n",
    "Durante el periodo **2023-2024**, coincidente con el **Fenómeno de El Niño**, se observa un **aumento notable de casos**, especialmente en cabeceras municipales. Esto puede explicarse por la **mayor actividad del mosquito vector en zonas urbanas**, favorecida por acumulación de agua, condiciones de saneamiento limitadas y la alta densidad poblacional. En centros poblados y áreas rurales dispersas, el aumento es mucho menor, reflejando la menor exposición y densidad de población.\n",
    "\n",
    "En **2024**, la **mayor concentración de casos** se registra entre **marzo y julio (meses 3 a 7)**, lo que coincide con la **temporada climática favorable para la reproducción del mosquito** y un mayor contacto humano con el vector, facilitando la transmisión del virus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea26e5a6",
   "metadata": {},
   "source": [
    "### **2.4 Enfoque regional: Región Caribe**\n",
    "\n",
    "En esta sección se aborda la dinámica del dengue en la **Región Caribe**, integrando diferentes niveles de análisis para ofrecer una visión completa de la situación. Se examina la **evolución mensual de casos**, lo que permite identificar patrones temporales y picos de incidencia a lo largo del tiempo. A su vez, se realiza una **comparación de casos por departamento**, con especial atención a Magdalena, con el fin de destacar las diferencias en la distribución de la enfermedad dentro de la región. Para complementar la perspectiva temporal y departamental, se utiliza un **mapa de calor** que refleja la intensidad de los casos en el espacio geográfico, facilitando la identificación de los focos de mayor incidencia. Además, se analiza la **jerarquía de los departamentos según el número de casos**, y finalmente, se profundiza en el nivel municipal para identificar los **municipios con mayor concentración de casos**, proporcionando así un panorama detallado desde la escala regional hasta la local.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50370bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENFOQUE REGIONAL: REGIÓN CARIBE\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Filtrar Región Caribe\n",
    "region_caribe = [\n",
    "    \"ATLANTICO\", \"BOLIVAR\", \"CESAR\", \"CORDOBA\",\n",
    "    \"GUAJIRA\", \"MAGDALENA\", \"SUCRE\",\n",
    "    \"SAN ANDRES, PROVIDENCIA Y SANTA CATALINA\"\n",
    "]\n",
    "\n",
    "df_caribe = df[df[\"Departamento_ocurrencia\"].str.upper().isin(region_caribe)].copy()\n",
    "df_caribe[\"FEC_NOT\"] = pd.to_datetime(df_caribe[\"FEC_NOT\"], errors=\"coerce\")\n",
    "\n",
    "# 1 Evolución mensual de casos\n",
    "serie_caribe = (\n",
    "    df_caribe\n",
    "    .assign(MES=df_caribe[\"FEC_NOT\"].dt.to_period(\"M\").dt.to_timestamp())\n",
    "    .groupby([\"MES\", \"Departamento_ocurrencia\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"Casos\")\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=serie_caribe,\n",
    "    x=\"MES\", y=\"Casos\",\n",
    "    hue=\"Departamento_ocurrencia\",\n",
    "    ax=axes[0],\n",
    "    marker=\"o\"\n",
    ")\n",
    "axes[0].set_title(\"Evolución mensual de casos en la Región Caribe\", fontsize=12)\n",
    "axes[0].set_xlabel(\"Mes\")\n",
    "axes[0].set_ylabel(\"Casos\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "axes[0].legend(title=\"Departamento\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "axes[0].set_xlim(serie_caribe[\"MES\"].min(), serie_caribe[\"MES\"].max())\n",
    "\n",
    "# 2 Casos por departamento (con Magdalena resaltado)\n",
    "casos_dep = (\n",
    "    df_caribe.groupby(\"Departamento_ocurrencia\")\n",
    "    .size()\n",
    "    .reset_index(name=\"Casos\")\n",
    "    .sort_values(\"Casos\", ascending=False)\n",
    ")\n",
    "\n",
    "sns.barplot(\n",
    "    data=casos_dep,\n",
    "    x=\"Casos\", y=\"Departamento_ocurrencia\",\n",
    "    palette=[\"#d62728\" if d == \"MAGDALENA\" else \"#1f77b4\" for d in casos_dep[\"Departamento_ocurrencia\"]],\n",
    "    ax=axes[1],\n",
    "    hue=\"Departamento_ocurrencia\",\n",
    "    legend=False\n",
    ")\n",
    "axes[1].set_title(\"Casos por departamento (resaltando Magdalena)\", fontsize=12)\n",
    "axes[1].set_xlabel(\"Número de casos\")\n",
    "axes[1].set_ylabel(\"Departamento\")\n",
    "axes[1].grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "# 3 Mapa de calor de casos — Región Caribe\n",
    "colombia = gpd.read_file(\"../data/raw/Colombia.geojson\")\n",
    "colombia[\"NOMBRE_DPT_NORM\"] = (\n",
    "    colombia[\"NOMBRE_DPT\"]\n",
    "    .str.upper()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"^LA\\s+\", \"\", regex=True)\n",
    "    .str.replace(r\"^EL\\s+\", \"\", regex=True)\n",
    "    .str.replace(r\"^DE(L)?\\s+\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "mapa_caribe = colombia[colombia[\"NOMBRE_DPT_NORM\"].isin(region_caribe)].copy()\n",
    "caribe_map = mapa_caribe.merge(\n",
    "    casos_dep.assign(Departamento_ocurrencia=casos_dep[\"Departamento_ocurrencia\"].str.upper().str.strip()),\n",
    "    left_on=\"NOMBRE_DPT_NORM\",\n",
    "    right_on=\"Departamento_ocurrencia\",\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "caribe_map.plot(\n",
    "    column=\"Casos\",\n",
    "    cmap=\"Reds\",\n",
    "    linewidth=0.8,\n",
    "    edgecolor=\"gray\",\n",
    "    legend=True,\n",
    "    ax=axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Mapa de calor de casos — Región Caribe\", fontsize=12)\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "\n",
    "# 4 Municipios con más casos (top 20)\n",
    "casos_mun = (\n",
    "    df_caribe.groupby([\"Departamento_ocurrencia\", \"Municipio_ocurrencia\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"Casos\")\n",
    "    .sort_values(\"Casos\", ascending=False)\n",
    ")\n",
    "top_municipios = casos_mun.head(20)\n",
    "\n",
    "sns.barplot(\n",
    "    data=top_municipios,\n",
    "    x=\"Casos\", y=\"Municipio_ocurrencia\",\n",
    "    hue=\"Departamento_ocurrencia\",\n",
    "    dodge=False,\n",
    "    palette=\"tab10\",\n",
    "    ax=axes[3]\n",
    ")\n",
    "\n",
    "axes[3].set_title(\"Municipios con mayor número de casos — Región Caribe\", fontsize=12)\n",
    "axes[3].set_xlabel(\"Casos\")\n",
    "axes[3].set_ylabel(\"Municipio\")\n",
    "axes[3].legend(title=\"Departamento\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "axes[3].grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "# Ajustes finales\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Enfoque regional: Región Caribe - Dengue en Colombia\", fontsize=16, fontweight=\"bold\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a870f",
   "metadata": {},
   "source": [
    "Entre 2022 y 2024, la **Región Caribe** mostró un comportamiento variable del dengue, con picos de incidencia en distintos departamentos a lo largo del tiempo. En 2024, **Bolívar** y **Atlántico** registraron un aumento notable de casos, coincidiendo con periodos de mayor actividad del vector y posibles efectos del **Fenómeno de El Niño (2023–2024)**, que pudieron favorecer la proliferación de mosquitos y la transmisión de la enfermedad.\n",
    "\n",
    "El análisis espacial confirma estas diferencias: los departamentos con mayor número de casos, como Bolívar, Atlántico, Cordoba, Sucre y Cesar, destacan con tonalidades más intensas en el **mapa de calor regional**, mientras que Magdalena se presenta con menor registro de casos. Esta distribución refleja la influencia de factores como la densidad poblacional, la urbanización y la eficiencia de los sistemas de notificación, que facilitan la detección y reporte de casos en áreas urbanas más consolidadas.\n",
    "\n",
    "A nivel municipal, los centros urbanos más grandes concentran la mayoría de los casos. **Barranquilla**, **Cartagena** y **Montería** lideran los reportes, evidenciando cómo la concentración poblacional y la urbanización favorecen la propagación del dengue. En Magdalena, **Santa Marta** muestra una incidencia menor, posiblemente asociada a la dispersión de la población urbana.\n",
    "\n",
    "> **Nota:** Durante la revisión del conjunto de datos a nivel departamental, se identificó la presencia de **33 departamentos en lugar de los 32 oficiales**, debido a la existencia de un grupo de registros con el valor *\"EXTERIOR\"*.  \n",
    "> Estos registros corresponden a **casos notificados fuera del territorio nacional**, por lo que serán **filtrados en la fase de limpieza** empleando la variable **`COD_PAIS_O`**, conservando únicamente aquellos cuyo código corresponda a **Colombia**.  \n",
    "> Asimismo, se detectaron **inconsistencias en los nombres de municipios**, como la aparición de *\"Santa Martha\"*, que podrían afectar la correcta asignación de casos.  \n",
    "> No obstante, dado que esta variable **no tiene un peso determinante en el análisis nacional**, no se aplicará una corrección.  \n",
    "> En caso de desarrollar un **análisis analítico o predictivo a nivel municipal**, se recomienda **normalizar los nombres de municipios** o, preferiblemente, **utilizar los códigos oficiales** del dataset, ya que diferencias como entre *\"Santa Marta\"* y *\"Santa Martha\"* pueden generar **pérdida o duplicación de registros**.  \n",
    "> Para los fines actuales, centrados en la **escala nacional**, dichas inconsistencias **no alteran los resultados del estudio**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a9f1e",
   "metadata": {},
   "source": [
    "### **2.5 Exploración de la distribución de variables numéricas**\n",
    "\n",
    "En esta sección se analiza el comportamiento de las **variables numéricas** del conjunto de datos, con el objetivo de evaluar su distribución y así seleccionar el **estadístico de correlación más adecuado** para el estudio. Dado que nos interesa principalmente la variable de entrada `FEC_NOT` (fecha de notificación) y la variable de salida `número de casos`, este análisis permitirá decidir de manera informada qué tipo de correlación aplicar en la exploración posterior de relaciones.\n",
    "\n",
    "Para nuestro estudio, considerando que ambas variables son **numéricas**, las correlaciones posibles se limitan a dos tipos principales:  \n",
    "- **Paramétrica (Pearson):** adecuada si las variables presentan una **distribución aproximadamente normal** y se busca medir relaciones lineales.  \n",
    "- **No paramétrica (Spearman):** más robusta frente a distribuciones no normales.\n",
    "\n",
    "Para este análisis se incluyen únicamente **variables numéricas continuas, discretas y binarias**, así como **variables temporales derivadas convertidas a formato ordinal**. Se excluyen variables categóricas multiclase y códigos administrativos que no aportan información cuantitativa directa (`TIP_CAS`, `UNI_MED`, códigos de departamentos, nacionalidad, entre otros), así como la variable **`EDAD`**, dado que previamente se creó una variable derivada llamada `EDAD_ANIOS`, que representa la edad estandarizada en años.\n",
    "\n",
    "> **Nota:** Previo a la visualización, la variable **`estrato`** fue **normalizada a tipo numérico**, ya que originalmente presentaba una mezcla de valores nulos, flotantes y enteros. Los valores no numéricos o ausentes se reemplazaron por **0**, unificando la variable y evitando errores durante el análisis.<br>\n",
    "> Adicionalmente, se incorporó una **variable temporal derivada de la fecha de notificación**, agrupada por **semana epidemiológica** (`FECHA_SEMANA`), para analizar la evolución temporal de los casos de forma coherente, representando el paso del tiempo en unidades semanales sin alterar la secuencia original de los registros.  \n",
    "\n",
    "> **Nota Metodológica:** Aunque en la práctica para nuestro estudio solo se utilizará `FEC_NOT` agregada por semana y complementada con derivados temporales (como rezagos, tendencia y estacionalidad), el análisis de distribución y correlación se mantiene como una buena práctica metodológica.\n",
    "Este paso ofrece un marco de referencia sólido para la selección de estadísticos adecuados y facilita la replicación y extensión del análisis a otros conjuntos de datos o variables predictivas en futuros estudios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc373351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a numérico, reemplazar nulos o valores no válidos por 0, y convertir a int\n",
    "df['estrato'] = pd.to_numeric(df['estrato'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Crear una variable temporal derivada que representa el inicio de la semana epidemiológica\n",
    "df['FECHA_SEMANA'] = df['FEC_NOT'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "\n",
    "# Crear un dataframe solo con variables numéricas y temporales para análisis\n",
    "df_numeric = df.select_dtypes(include=['number', 'datetime64[ns]']).copy()\n",
    "\n",
    "# Convertir columnas de tipo fecha a formato ordinal (para posteriormente el calculo de correlación)\n",
    "for col in df_numeric.select_dtypes(include='datetime64[ns]').columns:\n",
    "    df_numeric[col] = df_numeric[col].map(lambda x: x.toordinal())\n",
    "\n",
    "# Filtrar columnas válidas\n",
    "df_numeric = df_numeric.loc[:, df_numeric.nunique() > 1]\n",
    "\n",
    "# Excluir columnas no relevantes para el análisis\n",
    "columnas_a_excluir = [\n",
    "    'COD_PRE', 'COD_SUB', 'UNI_MED', 'nacionalidad',\n",
    "    'COD_PAIS_O', 'COD_DPTO_O', 'COD_MUN_O',\n",
    "    'AREA','PER_ETN',\n",
    "    'COD_PAIS_R', 'COD_DPTO_R', 'COD_MUN_R',\n",
    "    'COD_DPTO_N', 'COD_MUN_N',\n",
    "    'fuente', 'TIP_CAS', 'AJUSTE', 'Estado_Final_de_caso',\n",
    "    'FM_FUERZA', 'FM_UNIDAD', 'FM_GRADO',\n",
    "    'EDAD', 'CONSECUTIVE', 'consecutive_origen'\n",
    "]\n",
    "df_numeric = df_numeric.drop(columns=[c for c in columnas_a_excluir if c in df_numeric.columns])\n",
    "\n",
    "df_numeric.hist(edgecolor='black', linewidth=1.2, bins=30)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 15)\n",
    "plt.suptitle('Distribución de variables numéricas', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60daac6c",
   "metadata": {},
   "source": [
    "Las variables analizadas no presentan una **distribución normal**, ya que no muestran forma de campana uniforme, sino que presentan patrones sesgados o concentraciones en ciertos valores. Por esta razón, el **estadístico más adecuado para evaluar posibles relaciones entre estas variables numéricas** es **Spearman**, que es un método **no paramétrico** y más robusto ante distribuciones no normales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02872bf",
   "metadata": {},
   "source": [
    "### **2.6 Exploración de Relaciones entre Variables Numéricas**\n",
    "\n",
    "En este bloque se examinan las relaciones entre las **variables numéricas** del conjunto de datos mediante una **matriz de correlación**, con el objetivo de identificar posibles asociaciones, patrones o dependencias que puedan ser relevantes para el análisis descriptivo y la fase posterior de modelado predictivo.  \n",
    "\n",
    "Dado que en la etapa previa se determinó que las variables **no presentan una distribución normal**, el **estadístico de correlación más apropiado** para este análisis es **Spearman**.  \n",
    "\n",
    "La matriz resultante permite detectar posibles **vínculos entre variables temporales, demográficas y de ocurrencia de casos**, aportando una primera aproximación a cómo podrían interactuar estos factores dentro del comportamiento general del dengue.  \n",
    "\n",
    "> **Nota:** En este análisis se consideran únicamente **variables numéricas** y **temporales derivadas**, excluyendo las categóricas multiclase. Sin embargo, para estudios futuros sería valioso complementar este enfoque con el análisis de relaciones entre **variables categóricas o mixtas**. Esto permitiría explorar si variables como `TIP_CASO` o la pertenencia a grupos poblacionales (`GP_*`) están asociadas con la **edad de los pacientes**  o la **distribución de casos por región**, lo cual podría fortalecer la **identificación de factores de riesgo** y **mejorar los modelos predictivos para casos con mayor desegregación**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e16041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación\n",
    "corr = df_numeric.corr(method='spearman')\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    cmap='coolwarm',\n",
    "    square=True,\n",
    "    cbar=True,\n",
    "    linewidths=0,\n",
    "    vmin=-0.6, vmax=1\n",
    ")\n",
    "plt.title('Matriz de Correlación entre Variables Numéricas y Temporales', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b4d22e",
   "metadata": {},
   "source": [
    "La matriz de correlación indica que la mayoría de las variables numéricas del estudio **no presentan correlaciones fuertes entre sí**, lo que sugiere una **baja redundancia** y una **mayor independencia** entre los indicadores analizados.  \n",
    "\n",
    "No obstante, se observan algunas excepciones esperables:  \n",
    "\n",
    "- Las variables de grupo poblacional (`GP_*`) muestran una **correlación inversa con `GP_OTROS`**, lo cual era previsible, ya que los individuos que no pertenecen a ninguno de los grupos específicos se clasifican en la categoría **\"Otros\"**.  \n",
    "\n",
    "- La variable auxiliar `FECHA_SEMANA` (convertida a formato ordinal), creada para evaluar posibles relaciones temporales, **no presenta correlación significativa con la mayoría de las variables del conjunto**. Las únicas excepciones observadas son:  \n",
    "  - `ANO` y `FEC_NOT`, lo cual es lógico dado que `FECHA_SEMANA` es una derivada de la fecha de notificación.  \n",
    "  - `SEMANA`, mostrando una **ligera correlación positiva**, coherente con la estructura temporal de los datos.  \n",
    "\n",
    "En general, estos resultados confirman que la variable temporal derivada y las demás variables numéricas mantienen una baja interdependencia, lo que facilita su uso en análisis posteriores y modelado predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8d6b6",
   "metadata": {},
   "source": [
    "# **II. Diseño de experimentos y recolección de resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc257d2",
   "metadata": {},
   "source": [
    "En esta fase se describen las estrategias aplicadas para **preparar los datos** de acuerdo con las necesidades identificadas durante la inspección y exploración del conjunto de datos. El objetivo principal es garantizar la coherencia, calidad y pertinencia de la información utilizada en los modelos predictivos.\n",
    "\n",
    "Las acciones realizadas incluyen la selección de variables, filtrado de registros, creación de campos derivados y transformaciones.\n",
    "\n",
    "De esta manera, el conjunto final de datos queda depurado, estructurado y listo para su uso en los distintos métodos de modelado.\n",
    "\n",
    "Asimismo, se detallarán los **experimentos realizados para ajustar los parámetros** de cada uno de los métodos considerados, buscando alcanzar el mejor desempeño posible sobre el conjunto de entrenamiento y posteriormente evaluar la capacidad de generalización sobre un conjunto de prueba independiente.\n",
    "\n",
    "Los métodos a implementar incluyen: regresión multivariada, árboles de decisión, Random Forest y redes neuronales (MLP y DNN).\n",
    "Para la optimización de hiperparámetros se utilizará GridSearchCV, herramienta que permite automatizar la búsqueda de combinaciones de parámetros y aplicar una estrategia de validación cruzada, garantizando la robustez y reproducibilidad de los resultados experimentales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd1ef4",
   "metadata": {},
   "source": [
    "### **3.1 Estandarización de nombres de variables**\n",
    "\n",
    "Como primer paso en la preparación del conjunto de datos, se realizó la **estandarización de los nombres de las columnas**, convirtiendo todos los identificadores de variables a **minúsculas**.  \n",
    "\n",
    "Esta práctica tiene el propósito de **facilitar el manejo del dataset** durante las etapas posteriores, evitando posibles **errores de escritura o referencia** derivados del uso inconsistente de mayúsculas y minúsculas en los nombres de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984288c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir todos los nombres de columnas a minúsculas\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd721ec",
   "metadata": {},
   "source": [
    "Se aplicó una conversión a todos los nombres de columnas a minúsculas mediante el método `str.lower()`. Esta estandarización mejora significativamente la legibilidad del código, facilita la manipulación del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87630ff3",
   "metadata": {},
   "source": [
    "### **3.2 Filtrado de Casos**\n",
    "\n",
    "A continuación haremos 2 tipos de filtrados el primero para conseguir los casos confirmados y el segundo para obtener todos los confirmados del pais colombia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c8781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# casos iniciales del dataset\n",
    "total_casos = df.shape[0]\n",
    "\n",
    "# filtrado por casos confirmados\n",
    "df_casos = df[df[\"confirmados\"] == 1]\n",
    "\n",
    "# Cantidad inicial de casos confirmados en Colombia\n",
    "total_confirmados = df_casos.shape[0]\n",
    "\n",
    "# filtrado por país de ocurrencia (Colombia)\n",
    "df_casos = df_casos[df_casos[\"cod_pais_o\"] == 170]\n",
    "\n",
    "# Cantidad después del filtrado\n",
    "total_final = df_casos.shape[0]\n",
    "\n",
    "# Cantidad eliminada\n",
    "eliminados = total_casos - total_final\n",
    "\n",
    "print(f\"Registros iniciales: {total_casos}\")\n",
    "print(f\"Registros iniciales confirmados: {total_confirmados}\")\n",
    "print(f\"Registros confirmados y ocurridos en Colombia: {total_final}\")\n",
    "print(f\"Registros eliminados: {eliminados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095c49c",
   "metadata": {},
   "source": [
    "Este filtrado garantiza que el modelado se realice únicamente con casos confirmados ocurridos en Colombia, lo que mejora sustancialmente la confiabilidad de las predicciones sobre la tendencia semanal de dengue. Al basarse en criterios epidemiológicos validados, se fortalece la calidad del análisis y se asegura que las decisiones derivadas del modelo estén respaldadas por evidencia sólida y trazable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d35db5",
   "metadata": {},
   "source": [
    "### **3.3 Selección de variables relevantes para el modelado**\n",
    "\n",
    "En esta etapa se definieron las **variables de interés** que serán utilizadas en la construcción del modelo predictivo.  \n",
    "Del total de **73 variables disponibles** en el conjunto de datos original, se seleccionó únicamente la variable **`fec_not` (fecha de notificación)**, al ser la que representa de manera más directa la **dinámica temporal** del reporte de casos de dengue.  \n",
    "\n",
    "A partir de esta variable se construirán 2 **variables derivadas**, que serán **`fec_semana`** y `casos` , la cual agrupa los registros por **semana epidemiológica**, permitiendo obtener el **número de casos semanales**.  \n",
    " \n",
    "Esta decisión se sustenta en los resultados de la fase de exploración de datos, donde se identificó que las demás variables aportan poco valor al objetivo principal: capturar el comportamiento del dengue a nivel nacional, sirviendo como base para la predicción de casos en periodos futuros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515101a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Selección y agregación semanal\n",
    "df_casos = df_casos[[\"fec_not\"]].copy()\n",
    "\n",
    "# Convertir a inicio de semana epidemiológica (periodo semanal -> start_time)\n",
    "df_casos[\"fec_semana\"] = df_casos[\"fec_not\"].dt.to_period(\"W\").apply(lambda r: r.start_time)\n",
    "\n",
    "df_pred = df_casos.groupby(\"fec_semana\").size().reset_index(name=\"casos\")\n",
    "df_pred = df_pred.sort_values(\"fec_semana\").reset_index(drop=True)\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(\"Primeras filas del DataFrame semanal de casos confirmados:\")\n",
    "print(df_pred.head())\n",
    "\n",
    "# Visualizar la evolución temporal original\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df_pred['fec_semana'], df_pred['casos'], color='tab:blue')\n",
    "plt.title('Evolución semanal de casos de dengue')\n",
    "plt.xlabel('Semana epidemiológica')\n",
    "plt.ylabel('Casos notificados')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19367b8",
   "metadata": {},
   "source": [
    "Con base en los hallazgos del análisis exploratorio de datos (EDA), se identificaron múltiples variables que no aportaban valor analítico al estudio. Entre ellas se encontraban variables constantes como `cod_eve`, `nombre_evento`, `va_sispro` y `con_fin`, cuyo contenido era invariable y por tanto irrelevante para el modelado. Asimismo, se detectaron variables técnicas y administrativas como `consecutive`, `consecutive_origen` y `cod_ase`, utilizadas para trazabilidad interna pero sin utilidad en el análisis epidemiológico. Finalmente, se excluyeron variables vacías o con alta proporción de valores faltantes, tales como `gru_pob`, `fec_def`, `cer_def`, `cbmte`, y otras relacionadas con información militar, que presentaban más del 99% de registros nulos, así como aquellas que, aunque habían sido útiles en análisis previos, no aportaban al objetivo actual.\n",
    "\n",
    "Además construyó una nueva variable denominada `casos`, obtenida mediante la agregación de los registros confirmados por semana, lo que permite capturar la dinámica temporal del fenómeno. Esta preparación estructural del dataset garantiza una base sólida y coherente para realizar transfromaciones y creación de variables derivadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048c12d",
   "metadata": {},
   "source": [
    "### **3.4 Separación de los registros hasta el 2024**\n",
    "\n",
    "Durante la fase de **análisis exploratorio**, se identificó la presencia de registros correspondientes al año **2025** dentro del conjunto de datos.  \n",
    "Dado que este año se encuentra **fuera del periodo principal de análisis (2022–2024)**, se decidió **separar estos registros en un conjunto independiente**.  \n",
    "\n",
    "El propósito inicial de esta separación era reservar los datos de 2025 como referencia para comparar posteriormente las predicciones generadas por el modelo con los valores reales observados en ese año. Sin embargo, luego de explorar estos registros se identificó que la notificación de 2025 presenta inconsistencias, ya que los casos semanales reportados aparecen en rangos muy bajos (por ejemplo, valores como 8 o 10 casos por semana), lo cual sugiere problemas de subregistro o errores en la actualización del sistema. Por esta razón, dichos datos no se utilizaron como punto de validación confiable.\n",
    "\n",
    "De esta forma, el conjunto de datos queda dividido en:\n",
    "\n",
    "- **`df_pred_2022_2024`** -> contiene los registros comprendidos entre **2022 y 2024**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ad0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar registros hasta el año 2024 (para modelado)\n",
    "df_pred_2022_2024 = df_pred[df_pred['fec_semana'].dt.year < 2025]\n",
    "\n",
    "# Mostrar tamaños de cada conjunto\n",
    "print(\"Registros para modelado (2022-2024):\", len(df_pred_2022_2024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52b633",
   "metadata": {},
   "source": [
    "### **3.5 Verificación de la coherencia y estacionariedad de la serie semanal**\n",
    "\n",
    "En esta etapa se verificará la **coherencia temporal** del dataset construido con frecuencia semanal, comprobando que no existan semanas faltantes dentro del rango de análisis.  \n",
    "Estos procedimientos permitirán garantizar la consistencia temporal del conjunto de datos y comprender mejor su comportamiento antes del proceso de modelado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961dd498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay semanas faltantes\n",
    "semanas_completas = pd.date_range(df_pred_2022_2024['fec_semana'].min(), df_pred_2022_2024['fec_semana'].max(), freq='W-MON')\n",
    "faltantes = semanas_completas.difference(df_pred_2022_2024['fec_semana']) # type: ignore\n",
    "print(f\"Semanas faltantes: {len(faltantes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b431b",
   "metadata": {},
   "source": [
    "debido a que no hay semanas faltantes, es decir, que tenemos una serie continua, por ende no hay que realizar un proceso de inmputación de datos para corregir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99773e80",
   "metadata": {},
   "source": [
    "### **3.6 Creación de variables de rezago (lags) y momentum**\n",
    "\n",
    "Para preparar los datos para modelado con regresión, árboles de decisión, Random Forest y redes neuronales, se generan variables derivadas que permitan a los modelos capturar dependencias temporales.\n",
    "\n",
    "1. **Variables de rezago (lags):**  \n",
    "   Se incluyen los valores de semanas anteriores (`lag_1`, `lag_2`, `lag_4`). Estas variables aportan memoria al modelo y permiten reconocer la evolución reciente del dengue. Por ejemplo, `lag_1` contiene el número de casos de la semana anterior.\n",
    "\n",
    "2. **Pendiente o momentum:**  \n",
    "   Se calcula la pendiente sobre una **ventana móvil de 4 semanas** (`momentum_4`). Esta variable refleja la tendencia reciente de los casos, indicando la dirección y velocidad del cambio.\n",
    "\n",
    "\n",
    "**Eliminación de valores faltantes:**  \n",
    "   La generación de lags y momentum produce registros con valores `NaN` al inicio de la serie. Estos registros se eliminan para dejar un dataset completo y listo para el modelado predictivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef510ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lags a generar\n",
    "lag_features = [1, 2, 4]\n",
    "\n",
    "# Dataset  (casos, con lags + tendencia + estacionalidad)\n",
    "dataset = df_pred_2022_2024[[\"fec_semana\", \"casos\"]].copy()\n",
    "\n",
    "# Agregar lags\n",
    "for lag in lag_features:\n",
    "    dataset[f\"lag_{lag}\"] = dataset[\"casos\"].shift(lag)\n",
    "\n",
    "# pendiente/momentum\n",
    "def calc_momentum(series, window=4):\n",
    "    \"\"\"Calcula la pendiente (slope) de una regresión lineal sobre una ventana móvil.\"\"\"\n",
    "    slopes = [np.nan] * (window - 1) \n",
    "    for i in range(window - 1, len(series)):\n",
    "        y = series[i - window + 1 : i + 1].values.reshape(-1, 1)\n",
    "        x = np.arange(window).reshape(-1, 1)\n",
    "        model = LinearRegression().fit(x, y)\n",
    "        slopes.append(model.coef_[0][0])\n",
    "    return slopes\n",
    "\n",
    "dataset[\"momentum_4\"] = calc_momentum(dataset[\"casos\"], window=4)\n",
    "\n",
    "# Eliminar NaNs generados por los lags\n",
    "dataset = dataset.dropna().reset_index(drop=True)\n",
    "\n",
    "# Resumen de tamaños\n",
    "print(\"Filas dataset:\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado\n",
    "data_utils.guardar_df(dataset, \"dataset_modelado_2022_2024\")\n",
    "data_utils.guardar_df(df_real_2025, \"dataset_real_2025\")\n",
    "\n",
    "print(\"Datasets guardados:\")\n",
    "print(\"- dataset_modelado_2022_2024\")\n",
    "print(\"- dataset_real_2025\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb52ecf",
   "metadata": {},
   "source": [
    "De esta manera, los datos limpios y estructurados quedan almacenados de forma segura y eficiente, listos para su uso en las etapas posteriores de modelado y análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd788e1",
   "metadata": {},
   "source": [
    "## **4. Descripción de experimentos realizados**\n",
    "\n",
    "Para la predicción semanal de los casos confirmados de dengue, se implementaron y compararon diversos modelos de aprendizaje supervisado, tanto lineales como no lineales, con el objetivo de identificar cuál ofrece el mejor desempeño en la estimación de la variable objetivo (`casos`). Además, para cada modelo se aplicó un proceso de ajuste de **hiperparámetros** utilizando `GridSearchCV` de *Scikit-learn*, el cual permite explorar de manera sistemática diferentes combinaciones de hiperparámetros mediante validación cruzada, con el propósito de identificar la configuración que minimice el error de predicción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Métricas de evaluación empleadas**\n",
    "\n",
    "Para evaluar el desempeño de los modelos entrenados se utilizaron métricas que permiten cuantificar el error de predicción y la capacidad explicativa del modelo.\n",
    "\n",
    "#### **Error Cuadrático Medio (MSE)**\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - t_i)^2\n",
    "$$\n",
    "\n",
    "El MSE mide el promedio del cuadrado de las diferencias entre los valores reales y los predichos. Penaliza de manera más fuerte los errores grandes, por lo que es sensible a valores atípicos.\n",
    "\n",
    "#### **Error Absoluto Medio (MAE)**\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - t_i|\n",
    "$$\n",
    "\n",
    "El MAE representa el promedio de las diferencias absolutas entre los valores reales y los predichos. Es más robusto ante valores extremos y mantiene las mismas unidades de la variable objetivo.\n",
    "\n",
    "#### **Coeficiente de Determinación (R²)**\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - t_i)^2}{\\sum_{i=1}^{n} (y_i - \\mu_y)^2}\n",
    "$$\n",
    "\n",
    "El coeficiente de determinación mide la proporción de la variabilidad total de la variable objetivo que es explicada por el modelo. Sus valores van desde \\( -\\infty \\) hasta 1, donde valores más cercanos a 1 indican un mejor ajuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54d139",
   "metadata": {},
   "source": [
    "### **4.2 Métrica principal para GridSearchCV**\n",
    "\n",
    "La métrica seleccionada para guiar el proceso de búsqueda de hiperparámetros fue el **Error Absoluto Medio (MAE)**, especificado en `Scikit-learn` como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_principal_metric = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5939682",
   "metadata": {},
   "source": [
    "Se eligió el MAE debido a que es robusto frente a valores atípicos, evitando que errores extremadamente grandes dominen la optimización del modelo. Además, mantiene la escala de la variable objetivo, lo que permite interpretar directamente el error promedio en casos semanales de dengue. En nuestro contexto epidemiológico, esto resulta especialmente útil para evaluar predicciones de brotes o picos de casos, donde el impacto de errores grandes podría sobreestimarse si se utilizara únicamente el MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af6726",
   "metadata": {},
   "source": [
    "### **4.3 Preparación del dataset y división en entrenamiento y prueba**\n",
    "\n",
    "Se cargó el dataset preprocesado correspondiente al período 2022–2024 y se separaron las **variables predictoras** (`X`) de la **variable objetivo** (`y`), que en este caso corresponde al número de **casos semanales de dengue**.\n",
    "\n",
    "Para mantener la **secuencia temporal** de los datos, la división entre entrenamiento y prueba se realizó de manera **secuencial**:\n",
    "\n",
    "- Se utilizó el **80% de los registros iniciales** como conjunto de entrenamiento (`X_train`, `y_train`), asegurando que el modelo aprenda de los datos históricos más antiguos.\n",
    "- El **20% restante** se reservó como conjunto de prueba o validación interna (`X_test`, `y_test`), utilizado para evaluar la capacidad de generalización del modelo sobre datos futuros.\n",
    "\n",
    "Adicionalmente, se conservó la columna `fec_semana` para poder graficar posteriormente la evolución de los casos semanales y comparar visualmente las predicciones con los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b695a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga y preparación del dataset para modelado\n",
    "df_modelado = pd.read_parquet(\"../data/processed/dataset_modelado_2022_2024.parquet\")\n",
    "\n",
    "# Separar variables predictoras y objetivo\n",
    "X = df_modelado.drop(columns=[\"casos\", \"fec_semana\"]).copy()\n",
    "y = df_modelado[\"casos\"].copy()\n",
    "\n",
    "# División secuencial (manteniendo el orden temporal)\n",
    "train_size = 0.8\n",
    "n_train = int(len(X) * train_size)\n",
    "\n",
    "X_train = X.iloc[:n_train].copy()\n",
    "y_train = y.iloc[:n_train].copy()\n",
    "\n",
    "X_test = X.iloc[n_train:].copy()\n",
    "y_test = y.iloc[n_train:].copy()\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {len(X_train)} registros\")\n",
    "print(f\"Conjunto de validación interna: {len(X_test)} registros\")\n",
    "\n",
    "# Si deseas, puedes conservar 'fec_semana' aparte para graficar luego:\n",
    "fec_train = df_modelado['fec_semana'].iloc[:n_train]\n",
    "fec_test = df_modelado['fec_semana'].iloc[n_train:]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graficar train\n",
    "plt.plot(df_modelado['fec_semana'].iloc[:len(X_train)], y_train, label=\"Train (Target)\", color=\"blue\", marker='o')\n",
    "\n",
    "# Graficar test\n",
    "plt.plot(df_modelado['fec_semana'].iloc[len(X_train):], y_test, label=\"Validation/Test (Real)\", color=\"orange\", marker='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Weekly Confirmed Cases: Train vs Validation\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Confirmed Cases\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b0ebd6",
   "metadata": {},
   "source": [
    "### **4.4 Implementación de modelos**\n",
    "\n",
    "A continuación, se presentan los distintos modelos entrenados para la predicción semanal de casos de dengue.  \n",
    "Cada subapartado incluye la descripción breve del modelo, el código de entrenamiento, predicción y evaluación utilizando métricas como MSE, MAE y R², así como gráficas comparativas entre valores reales y predichos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a52d6",
   "metadata": {},
   "source": [
    "#### **4.4.1 Regresión Multivariada**\n",
    "\n",
    "Modelo estadístico clásico que asume una relación lineal entre las variables predictoras y la variable objetivo. Intenta ajustar un hiperplano que minimice el error cuadrático medio entre los valores observados y los predichos. Es una base de referencia útil para comparar con modelos más complejos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7dffb",
   "metadata": {},
   "source": [
    ">**Nota:** En el caso de la **regresión multivariada**, no se aplicó `GridSearchCV` para ajuste de hiperparámetros, ya que el modelo lineal clásico **no posee parámetros ajustables** que afecten el desempeño de manera significativa.  \n",
    "El modelo aprende directamente los coeficientes óptimos mediante la **minimización del error cuadrático medio** durante el entrenamiento con los datos de entrada, por lo que el uso de validación cruzada para búsqueda de hiperparámetros no es necesario en este caso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88846c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = LinearRegression() \n",
    "\n",
    "mr.fit(X_train, y_train)\n",
    "y_test_pred = mr.predict(X_test)\n",
    "\n",
    "print(\"score train:\", mr.score(X_train, y_train))\n",
    "print(\"score test:\", mr.score(X_test, y_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fec_test, y_test, \n",
    "         label='Valores reales (Test)', color='orange', marker='o')\n",
    "plt.plot(fec_test, y_test_pred, \n",
    "         label='Predicción MR', color='blue', marker='o')\n",
    "plt.title(\"Regresión Multivariada: Predicción vs Valores Reales (Validación Interna)\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bdb81c",
   "metadata": {},
   "source": [
    "> **Nota:** En problemas de series temporales, como la predicción de casos semanales de dengue, no es adecuado usar validación cruzada aleatoria porque podría mezclar datos futuros con pasados. Por ello, se utiliza `TimeSeriesSplit(n_splits=3)` de *Scikit-learn*, que divide los datos de manera secuencial respetando el orden temporal, simulando la predicción de datos futuros a partir de información histórica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca588d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d73bba",
   "metadata": {},
   "source": [
    "#### **4.4.2 Árboles de Decisión**\n",
    "\n",
    "Algoritmo no paramétrico que divide el espacio de características en regiones mediante reglas de decisión. Permite capturar relaciones no lineales de forma sencilla y directa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b72193",
   "metadata": {},
   "source": [
    "##### **Intento #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dt={\n",
    "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "    'splitter': ['random'],\n",
    "    'max_depth':[4, 5, 6],\n",
    "    'min_samples_leaf':[4, 5, 6],\n",
    "    'min_samples_split':[4, 5, 6],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(DecisionTreeRegressor(random_state=42), param_dt, cv=tscv, n_jobs=-1, scoring=scoring_principal_metric)\n",
    "grid_dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f428ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = grid_dt.best_estimator_\n",
    "best_tree.fit(X_train,y_train)\n",
    "y_test_pred = best_tree.predict(X_test)\n",
    "\n",
    "print(\"score train\", best_tree.score(X_train,y_train))\n",
    "print(\"score test\", best_tree.score(X_test,y_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fec_test, y_test, label='Valores reales (Test)', color='orange', marker='o')\n",
    "plt.plot(fec_test, y_test_pred, label='Predicción DT', color='blue', marker='o')\n",
    "plt.title(\"Arboles de Decisión: Predicción vs Valores Reales (Validación Interna)\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dd12b9",
   "metadata": {},
   "source": [
    "##### **Intento #2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0509ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dt={\n",
    "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "    'splitter': ['random'],\n",
    "    'max_depth':[6, 7, 8],\n",
    "    'min_samples_leaf':[2, 3, 4],\n",
    "    'min_samples_split':[2, 3, 4],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(DecisionTreeRegressor(random_state=42), param_dt, cv=tscv, n_jobs=-1, scoring=scoring_principal_metric)\n",
    "grid_dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c482324",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = grid_dt.best_estimator_\n",
    "best_tree.fit(X_train,y_train)\n",
    "y_test_pred = best_tree.predict(X_test)\n",
    "\n",
    "print(\"score train\", best_tree.score(X_train,y_train))\n",
    "print(\"score test\", best_tree.score(X_test,y_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fec_test, y_test, label='Valores reales (Test)', color='orange', marker='o')\n",
    "plt.plot(fec_test, y_test_pred, label='Predicción DT', color='blue', marker='o')\n",
    "plt.title(\"Arboles de Decisión: Predicción vs Valores Reales (Validación Interna)\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea86ff",
   "metadata": {},
   "source": [
    "#### **4.4.3 Random Forest**\n",
    "\n",
    "Ensamble de múltiples árboles de decisión entrenados sobre subconjuntos aleatorios de los datos y de las variables predictoras. Al combinar los resultados de varios árboles, el modelo reduce la varianza y mejora la generalización, siendo más robusto frente al sobreajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21867705",
   "metadata": {},
   "source": [
    "##### **Intento #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d91fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "    'n_estimators': [5, 7, 10],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'min_samples_split': [4, 5, 6],\n",
    "    'min_samples_leaf': [4, 5, 6],\n",
    "    'bootstrap': [True],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_rf,\n",
    "    cv=tscv,\n",
    "    scoring=scoring_principal_metric,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eea9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = grid_rf.best_estimator_\n",
    "\n",
    "best_mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"score train\", best_mlp.score(X_train, y_train))\n",
    "print(\"score test\", best_mlp.score(X_test, y_test))\n",
    "\n",
    "y_test_pred = best_mlp.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fec_test, y_test, label='Valores reales (Test)', color='orange', marker='o')\n",
    "plt.plot(fec_test, y_test_pred, label='Predicción RF', color='blue', marker='o')\n",
    "plt.title(\"Random Forest: Predicción vs Valores Reales (Validación Interna)\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d4810",
   "metadata": {},
   "source": [
    "##### **Intento #2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52bda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "    'n_estimators': [7, 8, 9, 10],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'min_samples_split': [4, 5, 6],\n",
    "    'min_samples_leaf': [4, 5, 6],\n",
    "    'bootstrap': [True],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_rf,\n",
    "    cv=tscv,\n",
    "    scoring=scoring_principal_metric,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fadb4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = grid_rf.best_estimator_\n",
    "\n",
    "best_mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"score train\", best_mlp.score(X_train, y_train))\n",
    "print(\"score test\", best_mlp.score(X_test, y_test))\n",
    "\n",
    "y_test_pred = best_mlp.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fec_test, y_test, label='Valores reales (Test)', color='orange', marker='o')\n",
    "plt.plot(fec_test, y_test_pred, label='Predicción RF', color='blue', marker='o')\n",
    "plt.title(\"Random Forest: Predicción vs Valores Reales (Validación Interna)\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74997c98",
   "metadata": {},
   "source": [
    "##### **Intento #3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a49e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf = {\n",
    "    'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "    'n_estimators': [7, 8, 9],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'min_samples_split': [3, 4, 5],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'bootstrap': [True],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_rf,\n",
    "    cv=tscv,\n",
    "    scoring=scoring_principal_metric,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = grid_rf.best_estimator_\n",
    "\n",
    "best_mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"score train\", best_mlp.score(X_train, y_train))\n",
    "print(\"score test\", best_mlp.score(X_test, y_test))\n",
    "\n",
    "y_test_pred = best_mlp.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fec_test, y_test, label='Valores reales (Test)', color='orange', marker='o')\n",
    "plt.plot(fec_test, y_test_pred, label='Predicción RF', color='blue', marker='o')\n",
    "plt.title(\"Random Forest: Predicción vs Valores Reales (Validación Interna)\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b4a66a",
   "metadata": {},
   "source": [
    "#### **4.4.4 Redes Neuronales MLP**\n",
    "\n",
    "El MLP (Perceptrón Multicapa) es un modelo de red neuronal que consiste en capas densas de neuronas conectadas entre sí.  \n",
    "- Las **capas ocultas** aplican funciones de activación no lineales para capturar relaciones complejas entre las variables predictoras.  \n",
    "- La **capa de salida** utiliza activación lineal (`identity`) para predecir valores continuos, acorde con nuestro problema de regresión.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cda90",
   "metadata": {},
   "source": [
    "##### **Intento #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a2849",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mlp = {\n",
    "    'loss': ['squared_error', 'poisson'],\n",
    "    'hidden_layer_sizes': [(10,10), (15,15), (20,20)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': [300, 500],\n",
    "    'momentum': [0.9, 0.99],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "grid_mlp = GridSearchCV(\n",
    "    MLPRegressor(),\n",
    "    param_grid=param_mlp,\n",
    "    cv=tscv,\n",
    "    scoring=scoring_principal_metric,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_mlp.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4cb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = grid_mlp.best_estimator_\n",
    "\n",
    "best_mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"score train\", best_mlp.score(X_train, y_train))\n",
    "print(\"score test\", best_mlp.score(X_test, y_test))\n",
    "\n",
    "y_test_pred = best_mlp.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fec_test, y_test, label='Valores reales (Test)', color='orange', marker='o')\n",
    "plt.plot(fec_test, y_test_pred, label='Predicción MLP', color='blue', marker='o')\n",
    "plt.title(\"Perceptron Multicapa: Predicción vs Valores Reales (Validación Interna)\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f875ffa",
   "metadata": {},
   "source": [
    "##### **Intento 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c92389",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mlp = {\n",
    "    'loss': ['squared_error', 'poisson'],\n",
    "    'hidden_layer_sizes': [(5,20), (20, 5), (20,20)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'momentum': [0.9, 0.99],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "grid_mlp = GridSearchCV(\n",
    "    MLPRegressor(),\n",
    "    param_grid=param_mlp,\n",
    "    cv=tscv,\n",
    "    scoring=scoring_principal_metric,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_mlp.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = grid_mlp.best_estimator_\n",
    "\n",
    "best_mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"score train\", best_mlp.score(X_train, y_train))\n",
    "print(\"score test\", best_mlp.score(X_test, y_test))\n",
    "\n",
    "y_test_pred = best_mlp.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fec_test, y_test, label='Valores reales (Test)', color='orange', marker='o')\n",
    "plt.plot(fec_test, y_test_pred, label='Predicción MLP', color='blue', marker='o')\n",
    "plt.title(\"Perceptron Multicapa: Predicción vs Valores Reales (Validación Interna)\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d0afd",
   "metadata": {},
   "source": [
    "##### **4.4.5 Redes Neuronales DNN**\n",
    "\n",
    "Para este apartado se implementó un modelo basado en **Long Short-Term Memory (LSTM)**, una arquitectura diseñada específicamente para secuencias temporales. Las LSTM permiten capturar dependencias a corto y largo plazo en la serie, lo cual resulta particularmente útil en contextos epidemiológicos. La salida del modelo se obtiene a través de una capa densa final.\n",
    "\n",
    "Antes del entrenamiento fue necesario realizar una nueva partición de los datos. En lugar de aplicar una división convencional **(por ejemplo 60/20/20 o 70/15/15)**, se optó por dividir el conjunto de prueba en dos partes iguales (50% para validación y 50% para test final), dado que era necesario conservar suficientes observaciones sin prescindir de un conjunto de validación. Esta validación adicional permite monitorear el entrenamiento y aplicar técnicas como early stopping sin reducir de forma significativa el tamaño del test final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceddcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.5\n",
    "n_validation = int(len(X_test) * validation_size)\n",
    "\n",
    "X_validation = X_test.iloc[:n_validation].copy()\n",
    "y_validation = y_test.iloc[:n_validation].copy()\n",
    "\n",
    "X_test_2 = X_test.iloc[n_validation:].copy()\n",
    "y_test_2 = y_test.iloc[n_validation:].copy()\n",
    "\n",
    "print(f\"Validación: {len(X_validation)} filas\")\n",
    "print(f\"Test final: {len(X_test_2)} filas\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graficar train\n",
    "plt.plot(fec_train.iloc[:len(X_train)], y_train, label=\"train\", color=\"green\", marker='o')\n",
    "\n",
    "# Graficar validation\n",
    "plt.plot(fec_test.iloc[:len(X_validation)], y_validation, label=\"validation\", color=\"blue\", marker='o')\n",
    "\n",
    "# Graficar test\n",
    "plt.plot(fec_test.iloc[len(X_validation):], y_test_2, label=\"Test_2 (Real)\", color=\"orange\", marker='o')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Conjuntos de datos: Validacion y test_2\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Confirmed Cases\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e3fdaf",
   "metadata": {},
   "source": [
    "> **Nota sobre la preparación de datos para LSTM:**  \n",
    "> Las redes LSTM no operan con matrices 2D tradicionales como los modelos clásicos\n",
    ">\n",
    "> sino que requieren que la entrada tenga la forma: **(samples, timesteps, features)**.  \n",
    "> En este caso, cada observación semanal se trata como una secuencia de un solo paso temporal (**timesteps = 1**), por lo que fue necesario transformar las matrices originales de entrada a un arreglo 3D.  \n",
    ">  \n",
    "> Para lograrlo, se aplicó `np.expand_dims()` a cada conjunto de datos, generando las estructuras:  \n",
    "> - `X_train_lstm`  \n",
    "> - `X_validation_lstm`  \n",
    "> - `X_test_lstm`  \n",
    ">  \n",
    "> Esto garantiza que la LSTM reciba los datos en el formato esperado y pueda procesar correctamente las secuencias temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm = np.expand_dims(X_train.values, axis=1)\n",
    "X_validation_lstm = np.expand_dims(X_validation.values, axis=1)\n",
    "X_test_lstm = np.expand_dims(X_test_2.values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e68cd28",
   "metadata": {},
   "source": [
    "Para permitir el uso de `GridSearchCV` con redes LSTM fue necesario encapsular la arquitectura del modelo dentro de una función generadora. Esto se debe a que `GridSearchCV` ejecuta múltiples combinaciones de hiperparámetros y, en cada iteración, requiere instancias completamente nuevas y no entrenadas del modelo. Por ello, se definió la función `create_model()`, encargada de construir y compilar dinámicamente una red LSTM según los parámetros especificados (número de capas, unidades, activación, dropout y optimizador).    \n",
    "\n",
    "Estas configuraciones permiten explorar diversas arquitecturas durante la búsqueda de hiperparámetros, garantizando que cada combinación evaluada sea entrenada desde cero sin interferencias entre experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    input_shape,\n",
    "    lstm_units=(50,),          \n",
    "    lstm_activation='relu',\n",
    "    dropout=0.0,              \n",
    "    optimizer='adam'\n",
    "):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # LSTM layers\n",
    "    for i, units in enumerate(lstm_units):\n",
    "        \n",
    "        # Si NO es la última LSTM -> tiene que devolver secuencias sí o sí\n",
    "        rs =  i < len(lstm_units)-1\n",
    "            \n",
    "        model.add(layers.LSTM(\n",
    "            units,\n",
    "            activation=lstm_activation,\n",
    "            return_sequences=rs,\n",
    "            input_shape=input_shape if i == 0 else None   \n",
    "        ))\n",
    "        \n",
    "        if dropout > 0:\n",
    "            model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    #  Dense layers\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # Compilación\n",
    "    model.compile(optimizer=optimizer, loss=\"mean_absolute_error\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a1a504",
   "metadata": {},
   "source": [
    "##### **Intento #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68376cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "input_shape = (1, X_train.shape[1])\n",
    "\n",
    "regressor = KerasRegressor(\n",
    "    build_fn=create_model,\n",
    "    input_shape=input_shape,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "param_dnn = {\n",
    "    \"model__lstm_units\": [(32, 20, 30), (64, 50, 40)],\n",
    "    \"model__lstm_activation\": ['relu', 'leaky_relu', 'elu'],\n",
    "    \"model__dropout\": [0.0],\n",
    "    \"model__optimizer\": [\"adam\", \"rmsprop\", \"nadam\"],\n",
    "    \"batch_size\": [16, 20, 30],\n",
    "    \"epochs\": [50]\n",
    "}\n",
    "\n",
    "grid_dnn = GridSearchCV(\n",
    "    estimator=regressor,\n",
    "    param_grid=param_dnn,\n",
    "    scoring=scoring_principal_metric,\n",
    "    cv=tscv\n",
    ")\n",
    "\n",
    "grid_dnn.fit(X_train_lstm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dnn = grid_dnn.best_estimator_\n",
    "\n",
    "history = best_dnn.fit(\n",
    "    X_train_lstm,\n",
    "    y_train,\n",
    "    epochs=best_dnn.epochs,\n",
    "    batch_size=best_dnn.batch_size,\n",
    "    validation_data=(X_validation_lstm, y_validation),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_score = best_dnn.score(X_train_lstm, y_train)\n",
    "test_score  = best_dnn.score(X_test_lstm, y_test_2)\n",
    "\n",
    "print(\"score train:\", train_score)\n",
    "print(\"score test:\", test_score)\n",
    "\n",
    "y_test_pred = best_dnn.predict(X_test_lstm).ravel()\n",
    "\n",
    "mse = mean_squared_error(y_test_2, y_test_pred)\n",
    "mae = mean_absolute_error(y_test_2, y_test_pred)\n",
    "r2  = r2_score(y_test_2, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(fec_test.iloc[n_validation:], y_test_2, label=\"Real\", marker='o')\n",
    "plt.plot(fec_test.iloc[n_validation:], y_test_pred, label=\"Predicción DNN(LSTM)\", marker='o')\n",
    "\n",
    "plt.title(\"DNN(LSTM) - Predicción vs Real\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1be96",
   "metadata": {},
   "source": [
    "##### **Intento 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cdcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "input_shape = (1, X_train.shape[1])\n",
    "\n",
    "regressor = KerasRegressor(\n",
    "    build_fn=create_model,\n",
    "    input_shape=input_shape,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "param_dnn = {\n",
    "    \"model__lstm_units\": [(32, 20, 30), (64, 50, 40)],\n",
    "    \"model__lstm_activation\": ['relu', 'leaky_relu', 'elu'],\n",
    "    \"model__dropout\": [0.0],\n",
    "    \"model__optimizer\": [\"adam\", \"rmsprop\", \"nadam\"],\n",
    "    \"batch_size\": [16, 20, 30],\n",
    "    \"epochs\": [50]\n",
    "}\n",
    "\n",
    "grid_dnn = GridSearchCV(\n",
    "    estimator=regressor,\n",
    "    param_grid=param_dnn,\n",
    "    scoring=scoring_principal_metric,\n",
    "    cv=tscv\n",
    ")\n",
    "\n",
    "grid_dnn.fit(X_train_lstm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dnn = grid_dnn.best_estimator_\n",
    "\n",
    "history = best_dnn.fit(\n",
    "    X_train_lstm,\n",
    "    y_train,\n",
    "    epochs=best_dnn.epochs,\n",
    "    batch_size=best_dnn.batch_size,\n",
    "    validation_data=(X_validation_lstm, y_validation),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaccc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = best_dnn.score(X_train_lstm, y_train)\n",
    "test_score  = best_dnn.score(X_test_lstm, y_test_2)\n",
    "\n",
    "print(\"score train:\", train_score)\n",
    "print(\"score test:\", test_score)\n",
    "\n",
    "y_test_pred = best_dnn.predict(X_test_lstm).ravel()\n",
    "\n",
    "mse = mean_squared_error(y_test_2, y_test_pred)\n",
    "mae = mean_absolute_error(y_test_2, y_test_pred)\n",
    "r2  = r2_score(y_test_2, y_test_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, R2: {r2:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(fec_test.iloc[n_validation:], y_test_2, label=\"Real\", marker='o')\n",
    "plt.plot(fec_test.iloc[n_validation:], y_test_pred, label=\"Predicción DNN(LSTM)\", marker='o')\n",
    "\n",
    "plt.title(\"DNN(LSTM) - Predicción vs Real\")\n",
    "plt.xlabel(\"Semana Epidemiológica\")\n",
    "plt.ylabel(\"Casos Confirmados\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0a1a2",
   "metadata": {},
   "source": [
    "## **5. Explicación o Análisis de resultados obtenidos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96184d4",
   "metadata": {},
   "source": [
    "## regresion lineal:\n",
    "\n",
    "El modelo de Regresión Lineal entrenado sobre el dataset preprocesado presenta un desempeño sobresaliente, alcanzando un R² de 0.97 en el conjunto de validación interna, lo que indica que logra explicar aproximadamente el 97% de la variabilidad en los casos semanales transformados. Además, las métricas de error muestran valores bajos (MAE ≈ 190), evidenciando una capacidad precisa para aproximar los valores reales. La comparación gráfica entre predicciones y observaciones confirma que el modelo captura adecuadamente la tendencia general y los patrones de variación temporal, con ligeras desviaciones únicamente en cambios abruptos. En conjunto, estos resultados sugieren que la transformación aplicada al dataset mejora significativamente la linealidad del comportamiento temporal, permitiendo que un modelo simple como la regresión lineal alcance un nivel de desempeño altamente satisfactorio y adecuado para tareas de análisis y proyección.\n",
    "\n",
    "\n",
    "## random forest:\n",
    "\n",
    "Intento 1: En el primer intento con Random Forest se evaluó un amplio rango de hiperparámetros con validación temporal, obteniendo un desempeño moderado en la predicción de casos semanales. El modelo alcanzó un score de entrenamiento de 0.98, lo que evidencia un ajuste casi perfecto sobre los datos de entrenamiento. Sin embargo, el score en el conjunto de prueba fue de 0.70, indicando una reducción considerable del rendimiento y sugiriendo signos de sobreajuste. Las métricas de validación mostraron un MSE de 540 606.33, un R² de 0.71 y un MAE de 544.27, lo que indica que el modelo logra capturar la tendencia general pero presenta errores relevantes en semanas con variaciones abruptas. En la gráfica comparativa se observa que las predicciones mantienen la forma descendente del brote, aunque tienden a sobreestimar los valores reales en varios tramos. En conjunto, este primer ajuste del modelo ofrece un desempeño aceptable, pero evidencia la necesidad de seguir afinando la estructura del bosque o incorporar nuevas características para reducir el sesgo temporal y mejorar la precisión.\n",
    "\n",
    "Intento 2: En el segundo intento con Random Forest se amplió el rango de estimadores y se mantuvo la validación temporal para garantizar coherencia con la estructura secuencial del brote. El modelo logró un score de entrenamiento de 0.99, lo que confirma nuevamente un ajuste casi perfecto sobre los datos de entrenamiento. Por su parte, el score de prueba aumentó ligeramente hasta 0.73, indicando una mejora respecto al primer intento y una mejor capacidad de generalización. Las métricas obtenidas reflejan este avance: el MSE se redujo a 491 375.90, el R² aumentó a 0.73, y el MAE disminuyó a 522.09, sugiriendo una predicción algo más precisa y estable. En la gráfica se observa que el modelo continúa capturando la tendencia descendente del brote y corrige parcialmente las sobreestimaciones de semanas previas, aunque mantiene cierta tendencia a predecir valores superiores a los reales en algunos tramos. En conjunto, este segundo ajuste muestra una mejora consistente en la precisión del modelo, acercándose más al comportamiento real sin eliminar del todo la inclinación al sobreajuste.\n",
    "\n",
    "Intento 3: En el tercer intento se ajustaron nuevamente los hiperparámetros del Random Forest, incrementando ligeramente la complejidad del modelo mediante valores más flexibles para min_samples_split y min_samples_leaf. El rendimiento del modelo se mantuvo estable, con un score de entrenamiento de 0.99, lo que confirma el comportamiento altamente ajustado sobre los datos históricos. En el conjunto de prueba, el score disminuyó ligeramente a 0.71, acompañado de un MSE de 527 449.34, un R² de 0.71 y un MAE de 582.18, valores que indican una leve degradación respecto al desempeño alcanzado en el intento 2. En la gráfica se observa que el modelo sigue capturando la tendencia general del brote, especialmente el descenso prolongado, aunque persiste la tendencia a sobreestimar los valores reales en varias semanas, con un desfase más pronunciado en periodos de caída acelerada. Estos resultados sugieren que, aunque el modelo mantiene coherencia en la tendencia global, el ajuste de hiperparámetros realizado en este intento no produjo una mejora significativa y, de hecho, redujo levemente la precisión alcanzada previamente.\n",
    "\n",
    "## Perceptron multicapas: \n",
    "\n",
    "Intento 1: Primer intento con el Perceptrón Multicapa (MLP) se basó en una búsqueda de hiperparámetros de amplio espectro, utilizando validación temporal (TSCV) para seleccionar la arquitectura más efectiva. El modelo resultante demostró un ajuste sobresaliente con un score de entrenamiento  R² de 0.994, indicando que capturó casi toda la variabilidad histórica. Crucialmente, la capacidad de generalización fue notable, alcanzando un score de prueba de 0.971. Este valor lo posiciona al nivel de la Regresión Lineal, que también logró  R² de 0.97. Las métricas de error confirmaron este rendimiento: el MSE fue de 52 479.87 y, más significativamente, el MAE se ubicó en 187.69. Este error promedio absoluto de aproximadamente 188 casos por semana lo convierte en uno de los modelos más precisos. La representación gráfica de las predicciones valida su robustez, mostrando que la línea del MLP se superpone casi perfectamente a la de los valores reales, rastreando fielmente tanto la tendencia principal como las fluctuaciones semanales. En conclusión, este primer ajuste del MLP logró una precisión máxima, consolidándose como una alternativa de alto rendimiento comparable en exactitud a la Regresión Lineal, y superando con creces al Random Forest.\n",
    "\n",
    "Intento 2: En el segundo intento con el Perceptrón Multicapa, se ejecutó una nueva optimización de hiperparámetros, explorando distintas arquitecturas como (5, 20), (20, 5) y (20, 20), y ajustando los límites de las iteraciones. El modelo óptimo de este ensayo mantuvo un score de entrenamiento R² de 0.99, confirmando su capacidad de ajustarse casi perfectamente a los datos históricos. No obstante, se observó una leve pero clara degradación en la capacidad de generalización, con un score de prueba de 0.95. Este valor es inferior al R² de 0.97 logrado en el Intento 1. Las métricas de error reflejan esta reducción en precisión, con el MSE incrementándose a 80 432.24 y el MAE subiendo a 233.32. Aunque un MAE de 233 casos semanales sigue siendo un resultado sólido, es considerablemente peor que el MAE de 187.69 alcanzado previamente. La gráfica comparativa indica que, si bien el modelo rastrea la tendencia general, presenta una mayor tendencia a sobreestimar los valores reales en comparación con el Intento 1, especialmente en periodos de descenso rápido. Estos resultados sugieren que el ajuste de hiperparámetros de este segundo intento no fue tan efectivo y redujo levemente la precisión lograda en la primera iteración.\n",
    "\n",
    "## DNN: \n",
    "Intento 1: En el primer intento de entrenamiento del modelo DNN basado en una arquitectura LSTM se configuró una red simple con una única capa LSTM de 5 unidades, activación tanh, optimizador Adam y un rango reducido de tamaños de batch. Tras el proceso de búsqueda con GridSearchCV y el posterior ajuste del modelo con una tasa de aprendizaje fija de 0.01, se observaron resultados contrastantes entre las métricas de entrenamiento y prueba. El modelo alcanzó un desempeño muy elevado sobre el conjunto de entrenamiento (R² = 0.98), lo que indica una alta capacidad de ajuste a los patrones presentes en los datos históricos. Sin embargo, al evaluar su capacidad predictiva en el conjunto de prueba final, el rendimiento disminuyó significativamente (R² = 0.53), acompañado de un MAE de 202.19 casos y un MSE de 87.998. Este comportamiento evidencia sobreajuste: la red aprende bien los datos vistos pero tiene dificultades para generalizar a semanas no observadas. A pesar de esto, el modelo sí captura parcialmente la tendencia general de la serie, lo cual sugiere que la arquitectura es adecuada, pero insuficiente en complejidad y regularización para mejorar la estabilidad y precisión fuera de muestra.\n",
    "\n",
    "Intento 2: En el segundo intento se amplió el espacio de búsqueda del modelo DNN basado en LSTM, incorporando configuraciones con un mayor número de unidades ocultas (32, 64 y 128), diferentes funciones de activación y un rango más amplio de tamaños de batch y épocas de entrenamiento. Esta exploración permitió identificar combinaciones más robustas que mejoraron la capacidad de generalización del modelo. Los resultados muestran un rendimiento sobresaliente en entrenamiento (R² = 0.99), lo que evidencia una fuerte capacidad para aprender los patrones temporales presentes en los datos históricos. De manera más relevante, el desempeño sobre el conjunto de prueba alcanzó un R² = 0.75, con un MSE de 47,624.89 y un MAE de 160.43, valores que representan un avance importante respecto al intento anterior. Aunque persiste cierta brecha entre el rendimiento de entrenamiento y de prueba—indicando un nivel moderado de sobreajuste—el modelo ahora reproduce de manera más consistente las fluctuaciones reales en los casos semanales. En conjunto, este segundo intento demuestra que incrementar la complejidad del modelo y ampliar las combinaciones de hiperparámetros contribuye a mejorar notablemente la precisión predictiva del enfoque LSTM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dae1e7",
   "metadata": {},
   "source": [
    "# **III. Comparación de los modelos entrenados y conclusiones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a769fe3",
   "metadata": {},
   "source": [
    "## **6. Resúmen y comparación de Resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c947c",
   "metadata": {},
   "source": [
    "Al comparar los cinco modelos desarrollados, se observaron diferencias importantes en su capacidad de generalización sobre el conjunto de prueba. Los modelos clásicos de regresión lineal y perceptrón multicapa (MLP) fueron los de mejor desempeño global, ambos alcanzando un coeficiente de determinación R² cercano a 0.97, lo que indica una alta capacidad para explicar la variabilidad temporal de los casos semanales. El MLP obtuvo un MSE ligeramente menor (52 479) y un MAE más bajo (187.69) respecto a la regresión (MSE de 60 527 y MAE de 190.47), por lo que se posiciona como el mejor modelo entre los evaluados. El modelo DNN basado en LSTM mostró un desempeño intermedio, con un R² de 0.75 y un MAE de 160.43, destacándose por su capacidad para capturar relaciones temporales, aunque lejos de los mejores valores obtenidos por los modelos no secuenciales. En contraste, los modelos de árboles mostraron un desempeño significativamente menor: el Árbol de Decisión obtuvo un R² de 0.81, mientras que el Random Forest alcanzó únicamente 0.73, indicando que estas arquitecturas no lograron capturar de manera eficaz la estructura del problema pese a su mayor complejidad. En conjunto, los resultados muestran que, para este dataset y configuración, los modelos lineales y neuronales densos superan con claridad a los métodos basados en árboles, siendo el MLP la opción más precisa y estable para la tarea de predicción semanal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad274b3c",
   "metadata": {},
   "source": [
    "## **7. Conclusiones finales y Pasos a Seguir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfda1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c8ba0",
   "metadata": {},
   "source": [
    "## **Trabajo Futuro**\n",
    "\n",
    "Con el fin de mejorar los resultados obtenidos y ampliar la aplicabilidad del estudio, se plantean varias líneas de trabajo futuro:\n",
    "\n",
    "- **Ampliar la ventana temporal de análisis.**  \n",
    "  Incluir más años de información permitiría capturar ciclos epidemiológicos más amplios, fortalecer la detección de patrones estacionales y aumentar la capacidad predictiva de los modelos.\n",
    "\n",
    "- **Profundizar en el análisis por grupos poblacionales.**  \n",
    "  El dataset contiene variables asociadas a grupos étnicos; esto abre la posibilidad de realizar análisis estratificados o modelos independientes para cada grupo, con el fin de identificar diferencias relevantes en la dinámica del dengue.\n",
    "\n",
    "- **Incorporar perspectivas ocupacionales y socioeconómicas.**  \n",
    "  Variables como ocupación y estrato socioeconómico pueden aportar contexto sobre factores de riesgo. Analizar estos subgrupos permitiría desarrollar interpretaciones epidemiológicas más completas.\n",
    "\n",
    "- **Extender los modelos a niveles geográficos más específicos.**  \n",
    "  Además del nivel nacional, sería útil generar modelos predictivos a nivel departamental o municipal, especialmente en territorios con alta carga de enfermedad o patrones atípicos.\n",
    "\n",
    "- **Explorar modelos estadísticos especializados para series de tiempo (ARIMA, SARIMA).**  \n",
    "  La incorporación de modelos como ARIMA o SARIMA permitiría capturar dinámicas temporales más complejas. Para emplearlos adecuadamente sería necesario:\n",
    "  - usar la fecha como índice explícito de la serie,\n",
    "  - trabajar con una estructura estrictamente secuencial sin variables desordenadas,\n",
    "  - y verificar supuestos como estacionariedad y ruido blanco de los residuos.  \n",
    "  Este enfoque complementaría a los modelos de ML profundizando en la componente temporal del comportamiento epidemiológico.\n",
    "\n",
    "Estas líneas abren oportunidades para enriquecer los resultados, mejorar la robustez de las predicciones y aportar mayor valor epidemiológico al análisis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
