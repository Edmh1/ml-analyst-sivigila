{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04723445",
   "metadata": {},
   "source": [
    "## Contexto del Dataset\n",
    "Este dataset es originario del Sistema de Vigilancia de Salud Pública (SIVIGILA), que recopila y analiza datos sobre eventos que afectan la salud de la población colombiana como enfermedades (infecciosas, crónicas, etc.), factores de riesgo y otros sucesos de importancia en salud pública."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09fb599",
   "metadata": {},
   "source": [
    "## Descripción del Problema\n",
    "TODO: hacer descripción de la problematica\n",
    "\n",
    "Para llevar acabo este caso de uso, se utilizará el conjunto de datos disponible en: https://portalsivigila.ins.gov.co/Paginas/Buscador.aspx\n",
    "\n",
    "En el presente trabajo se pretende realizar un realizar un análisis exploratorio, limpieza, modelado y evaluación sobre el conjunto de datos epidemiológicos obtenidos del sistema SIVIGILA (Colombia) centrado en la patologia DENGUE en el periodo 2022-2024.\n",
    "\n",
    "#### Objetivos específicos:\n",
    "- Realizar análisis y pruebas con el dataset.\n",
    "- Aplicar técnicas de procesamiento al conjunto de datos.\n",
    "- Implementar modelos de aprendizaje de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a5b56",
   "metadata": {},
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b4acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Esto hace que cada vez que ejecutes una celda, Jupyter verifique si algún módulo local cambió y lo recargue automáticamente.\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "import dtale\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Agregar el directorio raíz del proyecto al sys.path para permitir importaciones de utilidades realizadas\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Importar la función directamente desde el paquete src para cargar los datos\n",
    "from src import data_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d40a1",
   "metadata": {},
   "source": [
    "### Carga Datos\n",
    "En esta sección se realiza una conversión de los archivos descargados desde el portal del SIVIGILA, utilizando el módulo de utilidades.\n",
    "Con la finalidad de acelerar el proceso posterior de cargado y lectura, dicha conversión se hará de formato .xlsx -> formato .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d85235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir archivos Excel a Parquet\n",
    "data_utils.convertir_excel_a_parquet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7149e70",
   "metadata": {},
   "source": [
    "Una vez realizada la conversión procedemos a cargar los datos en un diccionario usando el módulo de utilidades, de esta manera obtendremos los nombres de los archivos asociados a sus respectivos dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb985df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargaron 3 archivos Parquet desde C:\\Users\\edavi\\OneDrive - Universidad del Magdalena\\Universidad\\8° Semestre\\ia\\ml-analyst-sivigila\\data\\processed\n",
      "Nombres de los archivos cargados: ['Datos_2022_210', 'Datos_2023_210', 'Datos_2024_210']\n"
     ]
    }
   ],
   "source": [
    "# cargar datos .parquet\n",
    "dict_df = data_utils.cargar_archivos_parquet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6f98e",
   "metadata": {},
   "source": [
    "Verificamos si tenemos algún problema de consistencias de columnas en el conjuntos de dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dec7859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El Archivo de referencia para las columnas es: 'Datos_2024_210'\n",
      "\n",
      "Diferencias encontradas en el archivo'Datos_2022_210':\n",
      "Columnas adicionales no presentes en el archivo de referencia:\n",
      "    - consecutive_origen (tipo actual: int64)\n",
      "\n",
      "Diferencias encontradas en el archivo'Datos_2023_210':\n",
      "Columnas adicionales no presentes en el archivo de referencia:\n",
      "    - consecutive_origen (tipo actual: int64)\n",
      "\n",
      "Tipo de dato diferente en archivo 'Datos_2022_210', columna 'FM_UNIDAD': (esperado: object, actual: float64)\n",
      "Tipo de dato diferente en archivo 'Datos_2022_210', columna 'estrato': (esperado: float64, actual: object)\n",
      "Tipo de dato diferente en archivo 'Datos_2022_210', columna 'FM_GRADO': (esperado: object, actual: float64)\n",
      "Tipo de dato diferente en archivo 'Datos_2022_210', columna 'sem_ges': (esperado: float64, actual: object)\n",
      "Tipo de dato diferente en archivo 'Datos_2022_210', columna 'OCUPACION': (esperado: float64, actual: object)\n",
      "\n",
      "Tipo de dato diferente en archivo 'Datos_2023_210', columna 'estrato': (esperado: float64, actual: object)\n",
      "Tipo de dato diferente en archivo 'Datos_2023_210', columna 'sem_ges': (esperado: float64, actual: object)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"475\"\n",
       "            src=\"http://LaptopEdmh:40000/dtale/iframe/1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1cb6f9d2a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ref, columnas_en_comun = data_utils.verificar_referencia_columnas(dict_df)\n",
    "data_utils.verificar_tipo_columnas(dict_df, columnas_en_comun)\n",
    "\n",
    "dtale.show(df_ref, name=\"DataFrame de Referencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d0abc",
   "metadata": {},
   "source": [
    "**TODO:** describir el siguiente paso al ver inconsistencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a48227",
   "metadata": {},
   "source": [
    "Una vez solucionados los problemas de consistencia en las columnas en nuestro conjunto de datos se procede a unificar todos los archivos y\n",
    "guardarlos en un unico archivo de extensión parquet que será el archivo con el que se trabajara durante todo el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtenemos data frames unificados apartir del conjuntos de datos y los guardamos en un unico archivo de extensión csv\n",
    "df_full = data_utils.unir_df(dict_df)\n",
    "data_utils.guardar_df(df_full, 'datos_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05bf993",
   "metadata": {},
   "source": [
    "En esta sección se realiza la lectura del archivo parquet previamente generado, con el fin de disponer de los datos unificados para su posterior análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/datos_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25448f",
   "metadata": {},
   "source": [
    "### Detalles del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516e8bf",
   "metadata": {},
   "source": [
    "El dataset consta de 501729 entradas y 72 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682bd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1742c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
